{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train/'\n",
    "test_dir = 'data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper params\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into dataloaders (generator)\n",
    "train_transfomers  = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_transformers = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "train_data = datasets.ImageFolder(\n",
    "    train_dir, transform=train_transfomers\n",
    ")\n",
    "\n",
    "test_data = datasets.ImageFolder(\n",
    "    test_dir, transform=test_transformers\n",
    ")\n",
    "\n",
    "num_train = len(train_data)\n",
    "train_indices = list(range(num_train))\n",
    "\n",
    "num_test = len(test_data)\n",
    "test_indicies = list(range(num_test))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indicies)\n",
    "\n",
    "train_loader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Fashion MNIST class distribution')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distribution of data\n",
    "def get_class_distribution(dataset_obj):\n",
    "    idx2class = {v: k for k, v in dataset_obj.class_to_idx.items()}\n",
    "    count_dict = {k:0 for k, v in dataset_obj.class_to_idx.items()}\n",
    "    \n",
    "    for element in dataset_obj:\n",
    "        y_lbl = element[1]\n",
    "        y_lbl = idx2class[y_lbl]\n",
    "        count_dict[y_lbl] += 1\n",
    "    \n",
    "    return count_dict\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "data = get_class_distribution(train_loader.dataset)\n",
    "sns.barplot(\n",
    "    data=pd.DataFrame.from_dict([data]).melt(),  x = \"variable\", y=\"value\", hue=\"variable\"\n",
    ").set_title('Fashion MNIST class distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (4): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfer learning using resnet\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 10),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10.. Train loss: 2.155.. Test loss: 2.513.. Test accuracy: 0.105\n",
      "Epoch 1/10.. Train loss: 1.776.. Test loss: 3.211.. Test accuracy: 0.143\n",
      "Epoch 1/10.. Train loss: 1.624.. Test loss: 4.275.. Test accuracy: 0.148\n",
      "Epoch 1/10.. Train loss: 1.441.. Test loss: 2.102.. Test accuracy: 0.365\n",
      "Epoch 1/10.. Train loss: 1.406.. Test loss: 1.479.. Test accuracy: 0.519\n",
      "Epoch 1/10.. Train loss: 1.393.. Test loss: 1.423.. Test accuracy: 0.510\n",
      "Epoch 1/10.. Train loss: 1.426.. Test loss: 1.233.. Test accuracy: 0.589\n",
      "Epoch 1/10.. Train loss: 1.263.. Test loss: 1.327.. Test accuracy: 0.574\n",
      "Epoch 1/10.. Train loss: 1.295.. Test loss: 1.260.. Test accuracy: 0.576\n",
      "Epoch 1/10.. Train loss: 1.322.. Test loss: 1.216.. Test accuracy: 0.602\n",
      "Epoch 1/10.. Train loss: 1.238.. Test loss: 1.191.. Test accuracy: 0.595\n",
      "Epoch 1/10.. Train loss: 1.172.. Test loss: 1.174.. Test accuracy: 0.610\n",
      "Epoch 1/10.. Train loss: 1.282.. Test loss: 1.261.. Test accuracy: 0.571\n",
      "Epoch 1/10.. Train loss: 1.184.. Test loss: 1.219.. Test accuracy: 0.585\n",
      "Epoch 1/10.. Train loss: 1.238.. Test loss: 1.177.. Test accuracy: 0.583\n",
      "Epoch 1/10.. Train loss: 1.187.. Test loss: 1.123.. Test accuracy: 0.615\n",
      "Epoch 1/10.. Train loss: 1.181.. Test loss: 1.152.. Test accuracy: 0.598\n",
      "Epoch 1/10.. Train loss: 1.231.. Test loss: 1.133.. Test accuracy: 0.610\n",
      "Epoch 1/10.. Train loss: 1.123.. Test loss: 1.085.. Test accuracy: 0.626\n",
      "Epoch 1/10.. Train loss: 1.159.. Test loss: 1.060.. Test accuracy: 0.639\n",
      "Epoch 1/10.. Train loss: 1.109.. Test loss: 1.080.. Test accuracy: 0.622\n",
      "Epoch 1/10.. Train loss: 1.085.. Test loss: 1.072.. Test accuracy: 0.632\n",
      "Epoch 1/10.. Train loss: 1.037.. Test loss: 1.126.. Test accuracy: 0.611\n",
      "Epoch 1/10.. Train loss: 1.131.. Test loss: 1.118.. Test accuracy: 0.604\n",
      "Epoch 1/10.. Train loss: 1.132.. Test loss: 1.082.. Test accuracy: 0.624\n",
      "Epoch 1/10.. Train loss: 1.088.. Test loss: 1.156.. Test accuracy: 0.588\n",
      "Epoch 1/10.. Train loss: 1.215.. Test loss: 1.105.. Test accuracy: 0.618\n",
      "Epoch 1/10.. Train loss: 1.062.. Test loss: 1.050.. Test accuracy: 0.634\n",
      "Epoch 1/10.. Train loss: 1.022.. Test loss: 1.077.. Test accuracy: 0.625\n",
      "Epoch 1/10.. Train loss: 1.086.. Test loss: 1.079.. Test accuracy: 0.620\n",
      "Epoch 1/10.. Train loss: 1.056.. Test loss: 1.033.. Test accuracy: 0.639\n",
      "Epoch 1/10.. Train loss: 1.066.. Test loss: 1.041.. Test accuracy: 0.640\n",
      "Epoch 1/10.. Train loss: 1.083.. Test loss: 1.032.. Test accuracy: 0.643\n",
      "Epoch 1/10.. Train loss: 1.083.. Test loss: 1.074.. Test accuracy: 0.626\n",
      "Epoch 1/10.. Train loss: 1.115.. Test loss: 1.016.. Test accuracy: 0.647\n",
      "Epoch 1/10.. Train loss: 1.068.. Test loss: 1.014.. Test accuracy: 0.645\n",
      "Epoch 1/10.. Train loss: 1.143.. Test loss: 1.077.. Test accuracy: 0.627\n",
      "Epoch 1/10.. Train loss: 1.089.. Test loss: 1.030.. Test accuracy: 0.650\n",
      "Epoch 1/10.. Train loss: 1.043.. Test loss: 1.011.. Test accuracy: 0.646\n",
      "Epoch 1/10.. Train loss: 0.997.. Test loss: 1.008.. Test accuracy: 0.649\n",
      "Epoch 1/10.. Train loss: 1.146.. Test loss: 1.046.. Test accuracy: 0.634\n",
      "Epoch 1/10.. Train loss: 1.070.. Test loss: 1.058.. Test accuracy: 0.630\n",
      "Epoch 1/10.. Train loss: 0.986.. Test loss: 0.989.. Test accuracy: 0.659\n",
      "Epoch 1/10.. Train loss: 1.019.. Test loss: 1.015.. Test accuracy: 0.642\n",
      "Epoch 1/10.. Train loss: 1.015.. Test loss: 1.034.. Test accuracy: 0.648\n",
      "Epoch 1/10.. Train loss: 1.058.. Test loss: 0.988.. Test accuracy: 0.657\n",
      "Epoch 1/10.. Train loss: 1.091.. Test loss: 1.001.. Test accuracy: 0.651\n",
      "Epoch 1/10.. Train loss: 1.033.. Test loss: 1.011.. Test accuracy: 0.651\n",
      "Epoch 1/10.. Train loss: 1.057.. Test loss: 0.977.. Test accuracy: 0.655\n",
      "Epoch 1/10.. Train loss: 1.087.. Test loss: 0.986.. Test accuracy: 0.661\n",
      "Epoch 1/10.. Train loss: 1.060.. Test loss: 0.981.. Test accuracy: 0.656\n",
      "Epoch 1/10.. Train loss: 0.992.. Test loss: 0.987.. Test accuracy: 0.649\n",
      "Epoch 1/10.. Train loss: 1.021.. Test loss: 0.951.. Test accuracy: 0.663\n",
      "Epoch 1/10.. Train loss: 1.098.. Test loss: 0.964.. Test accuracy: 0.649\n",
      "Epoch 1/10.. Train loss: 0.969.. Test loss: 0.974.. Test accuracy: 0.651\n",
      "Epoch 1/10.. Train loss: 1.039.. Test loss: 0.996.. Test accuracy: 0.646\n",
      "Epoch 1/10.. Train loss: 1.052.. Test loss: 0.991.. Test accuracy: 0.644\n",
      "Epoch 1/10.. Train loss: 1.014.. Test loss: 0.950.. Test accuracy: 0.659\n",
      "Epoch 1/10.. Train loss: 1.013.. Test loss: 0.985.. Test accuracy: 0.652\n",
      "Epoch 1/10.. Train loss: 1.015.. Test loss: 0.958.. Test accuracy: 0.660\n",
      "Epoch 1/10.. Train loss: 1.048.. Test loss: 0.964.. Test accuracy: 0.656\n",
      "Epoch 1/10.. Train loss: 1.014.. Test loss: 0.970.. Test accuracy: 0.652\n",
      "Epoch 1/10.. Train loss: 0.959.. Test loss: 0.970.. Test accuracy: 0.655\n",
      "Epoch 1/10.. Train loss: 0.965.. Test loss: 1.002.. Test accuracy: 0.646\n",
      "Epoch 1/10.. Train loss: 1.001.. Test loss: 0.951.. Test accuracy: 0.656\n",
      "Epoch 1/10.. Train loss: 0.960.. Test loss: 0.971.. Test accuracy: 0.653\n",
      "Epoch 1/10.. Train loss: 1.035.. Test loss: 0.973.. Test accuracy: 0.650\n",
      "Epoch 1/10.. Train loss: 1.056.. Test loss: 0.955.. Test accuracy: 0.657\n",
      "Epoch 1/10.. Train loss: 0.981.. Test loss: 0.967.. Test accuracy: 0.652\n",
      "Epoch 1/10.. Train loss: 0.959.. Test loss: 0.994.. Test accuracy: 0.654\n",
      "Epoch 1/10.. Train loss: 1.066.. Test loss: 1.011.. Test accuracy: 0.631\n",
      "Epoch 1/10.. Train loss: 1.025.. Test loss: 0.942.. Test accuracy: 0.667\n",
      "Epoch 1/10.. Train loss: 1.024.. Test loss: 0.964.. Test accuracy: 0.657\n",
      "Epoch 1/10.. Train loss: 1.044.. Test loss: 0.948.. Test accuracy: 0.660\n",
      "Epoch 1/10.. Train loss: 0.993.. Test loss: 0.968.. Test accuracy: 0.660\n",
      "Epoch 1/10.. Train loss: 0.912.. Test loss: 0.941.. Test accuracy: 0.663\n",
      "Epoch 1/10.. Train loss: 0.986.. Test loss: 0.935.. Test accuracy: 0.670\n",
      "Epoch 1/10.. Train loss: 0.970.. Test loss: 0.962.. Test accuracy: 0.649\n",
      "Epoch 1/10.. Train loss: 1.031.. Test loss: 0.944.. Test accuracy: 0.664\n",
      "Epoch 1/10.. Train loss: 0.900.. Test loss: 0.926.. Test accuracy: 0.667\n",
      "Epoch 1/10.. Train loss: 0.951.. Test loss: 0.946.. Test accuracy: 0.656\n",
      "Epoch 1/10.. Train loss: 0.955.. Test loss: 0.935.. Test accuracy: 0.659\n",
      "Epoch 1/10.. Train loss: 0.986.. Test loss: 0.928.. Test accuracy: 0.666\n",
      "Epoch 1/10.. Train loss: 0.942.. Test loss: 0.957.. Test accuracy: 0.659\n",
      "Epoch 1/10.. Train loss: 0.984.. Test loss: 0.969.. Test accuracy: 0.660\n",
      "Epoch 1/10.. Train loss: 0.899.. Test loss: 0.956.. Test accuracy: 0.665\n",
      "Epoch 1/10.. Train loss: 0.966.. Test loss: 0.966.. Test accuracy: 0.658\n",
      "Epoch 1/10.. Train loss: 0.989.. Test loss: 0.936.. Test accuracy: 0.666\n",
      "Epoch 1/10.. Train loss: 1.034.. Test loss: 0.949.. Test accuracy: 0.659\n",
      "Epoch 1/10.. Train loss: 0.981.. Test loss: 0.946.. Test accuracy: 0.661\n",
      "Epoch 1/10.. Train loss: 0.995.. Test loss: 0.910.. Test accuracy: 0.671\n",
      "Epoch 1/10.. Train loss: 0.990.. Test loss: 0.937.. Test accuracy: 0.663\n",
      "Epoch 1/10.. Train loss: 0.892.. Test loss: 0.940.. Test accuracy: 0.668\n",
      "Epoch 2/10.. Train loss: 0.205.. Test loss: 0.923.. Test accuracy: 0.666\n",
      "Epoch 2/10.. Train loss: 0.899.. Test loss: 0.930.. Test accuracy: 0.675\n",
      "Epoch 2/10.. Train loss: 0.986.. Test loss: 0.934.. Test accuracy: 0.665\n",
      "Epoch 2/10.. Train loss: 0.902.. Test loss: 0.907.. Test accuracy: 0.671\n",
      "Epoch 2/10.. Train loss: 0.914.. Test loss: 0.898.. Test accuracy: 0.678\n",
      "Epoch 2/10.. Train loss: 0.916.. Test loss: 0.928.. Test accuracy: 0.673\n",
      "Epoch 2/10.. Train loss: 0.975.. Test loss: 0.916.. Test accuracy: 0.672\n",
      "Epoch 2/10.. Train loss: 0.973.. Test loss: 0.922.. Test accuracy: 0.673\n",
      "Epoch 2/10.. Train loss: 0.962.. Test loss: 0.994.. Test accuracy: 0.654\n",
      "Epoch 2/10.. Train loss: 0.901.. Test loss: 0.975.. Test accuracy: 0.653\n",
      "Epoch 2/10.. Train loss: 0.992.. Test loss: 0.953.. Test accuracy: 0.659\n",
      "Epoch 2/10.. Train loss: 0.975.. Test loss: 0.926.. Test accuracy: 0.667\n",
      "Epoch 2/10.. Train loss: 0.907.. Test loss: 0.951.. Test accuracy: 0.656\n",
      "Epoch 2/10.. Train loss: 0.933.. Test loss: 0.932.. Test accuracy: 0.668\n",
      "Epoch 2/10.. Train loss: 0.980.. Test loss: 0.941.. Test accuracy: 0.663\n",
      "Epoch 2/10.. Train loss: 0.909.. Test loss: 0.950.. Test accuracy: 0.665\n",
      "Epoch 2/10.. Train loss: 0.934.. Test loss: 0.934.. Test accuracy: 0.658\n",
      "Epoch 2/10.. Train loss: 0.897.. Test loss: 0.925.. Test accuracy: 0.666\n",
      "Epoch 2/10.. Train loss: 0.933.. Test loss: 0.904.. Test accuracy: 0.671\n",
      "Epoch 2/10.. Train loss: 0.908.. Test loss: 0.909.. Test accuracy: 0.675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10.. Train loss: 0.920.. Test loss: 0.931.. Test accuracy: 0.664\n",
      "Epoch 2/10.. Train loss: 0.890.. Test loss: 0.959.. Test accuracy: 0.661\n",
      "Epoch 2/10.. Train loss: 0.894.. Test loss: 0.932.. Test accuracy: 0.671\n",
      "Epoch 2/10.. Train loss: 0.930.. Test loss: 0.937.. Test accuracy: 0.667\n",
      "Epoch 2/10.. Train loss: 0.900.. Test loss: 0.954.. Test accuracy: 0.656\n",
      "Epoch 2/10.. Train loss: 0.956.. Test loss: 0.895.. Test accuracy: 0.674\n",
      "Epoch 2/10.. Train loss: 0.960.. Test loss: 0.895.. Test accuracy: 0.678\n",
      "Epoch 2/10.. Train loss: 0.885.. Test loss: 0.885.. Test accuracy: 0.681\n",
      "Epoch 2/10.. Train loss: 0.940.. Test loss: 0.889.. Test accuracy: 0.686\n",
      "Epoch 2/10.. Train loss: 0.992.. Test loss: 0.924.. Test accuracy: 0.665\n",
      "Epoch 2/10.. Train loss: 0.952.. Test loss: 0.922.. Test accuracy: 0.670\n",
      "Epoch 2/10.. Train loss: 0.898.. Test loss: 0.901.. Test accuracy: 0.675\n",
      "Epoch 2/10.. Train loss: 0.957.. Test loss: 0.890.. Test accuracy: 0.679\n",
      "Epoch 2/10.. Train loss: 0.989.. Test loss: 0.907.. Test accuracy: 0.676\n",
      "Epoch 2/10.. Train loss: 0.994.. Test loss: 0.920.. Test accuracy: 0.670\n",
      "Epoch 2/10.. Train loss: 0.955.. Test loss: 0.930.. Test accuracy: 0.661\n",
      "Epoch 2/10.. Train loss: 0.856.. Test loss: 0.913.. Test accuracy: 0.674\n",
      "Epoch 2/10.. Train loss: 0.989.. Test loss: 0.905.. Test accuracy: 0.673\n",
      "Epoch 2/10.. Train loss: 0.968.. Test loss: 0.895.. Test accuracy: 0.673\n",
      "Epoch 2/10.. Train loss: 0.875.. Test loss: 0.888.. Test accuracy: 0.680\n",
      "Epoch 2/10.. Train loss: 0.911.. Test loss: 0.885.. Test accuracy: 0.675\n",
      "Epoch 2/10.. Train loss: 0.887.. Test loss: 0.906.. Test accuracy: 0.672\n",
      "Epoch 2/10.. Train loss: 0.894.. Test loss: 0.891.. Test accuracy: 0.676\n",
      "Epoch 2/10.. Train loss: 0.894.. Test loss: 0.913.. Test accuracy: 0.670\n",
      "Epoch 2/10.. Train loss: 0.913.. Test loss: 0.976.. Test accuracy: 0.652\n",
      "Epoch 2/10.. Train loss: 0.948.. Test loss: 0.937.. Test accuracy: 0.664\n",
      "Epoch 2/10.. Train loss: 0.930.. Test loss: 0.909.. Test accuracy: 0.673\n",
      "Epoch 2/10.. Train loss: 0.857.. Test loss: 0.909.. Test accuracy: 0.668\n",
      "Epoch 2/10.. Train loss: 0.963.. Test loss: 0.910.. Test accuracy: 0.668\n",
      "Epoch 2/10.. Train loss: 0.918.. Test loss: 0.906.. Test accuracy: 0.675\n",
      "Epoch 2/10.. Train loss: 0.972.. Test loss: 0.909.. Test accuracy: 0.670\n",
      "Epoch 2/10.. Train loss: 0.872.. Test loss: 0.916.. Test accuracy: 0.672\n",
      "Epoch 2/10.. Train loss: 0.892.. Test loss: 0.920.. Test accuracy: 0.667\n",
      "Epoch 2/10.. Train loss: 0.967.. Test loss: 0.896.. Test accuracy: 0.671\n",
      "Epoch 2/10.. Train loss: 0.956.. Test loss: 0.910.. Test accuracy: 0.670\n",
      "Epoch 2/10.. Train loss: 0.935.. Test loss: 0.878.. Test accuracy: 0.684\n",
      "Epoch 2/10.. Train loss: 0.879.. Test loss: 0.876.. Test accuracy: 0.685\n",
      "Epoch 2/10.. Train loss: 0.988.. Test loss: 0.915.. Test accuracy: 0.672\n",
      "Epoch 2/10.. Train loss: 0.938.. Test loss: 0.888.. Test accuracy: 0.682\n",
      "Epoch 2/10.. Train loss: 0.859.. Test loss: 0.896.. Test accuracy: 0.668\n",
      "Epoch 2/10.. Train loss: 0.926.. Test loss: 0.862.. Test accuracy: 0.692\n",
      "Epoch 2/10.. Train loss: 0.868.. Test loss: 0.874.. Test accuracy: 0.682\n",
      "Epoch 2/10.. Train loss: 0.887.. Test loss: 0.876.. Test accuracy: 0.680\n",
      "Epoch 2/10.. Train loss: 0.921.. Test loss: 0.871.. Test accuracy: 0.683\n",
      "Epoch 2/10.. Train loss: 0.807.. Test loss: 0.867.. Test accuracy: 0.684\n",
      "Epoch 2/10.. Train loss: 0.896.. Test loss: 0.885.. Test accuracy: 0.685\n",
      "Epoch 2/10.. Train loss: 0.875.. Test loss: 0.879.. Test accuracy: 0.682\n",
      "Epoch 2/10.. Train loss: 0.966.. Test loss: 0.879.. Test accuracy: 0.684\n",
      "Epoch 2/10.. Train loss: 0.942.. Test loss: 0.884.. Test accuracy: 0.680\n",
      "Epoch 2/10.. Train loss: 0.977.. Test loss: 0.895.. Test accuracy: 0.680\n",
      "Epoch 2/10.. Train loss: 0.934.. Test loss: 0.871.. Test accuracy: 0.685\n",
      "Epoch 2/10.. Train loss: 0.926.. Test loss: 0.887.. Test accuracy: 0.676\n",
      "Epoch 2/10.. Train loss: 0.943.. Test loss: 0.859.. Test accuracy: 0.690\n",
      "Epoch 2/10.. Train loss: 0.940.. Test loss: 0.875.. Test accuracy: 0.685\n",
      "Epoch 2/10.. Train loss: 0.925.. Test loss: 0.875.. Test accuracy: 0.685\n",
      "Epoch 2/10.. Train loss: 0.923.. Test loss: 0.858.. Test accuracy: 0.687\n",
      "Epoch 2/10.. Train loss: 0.867.. Test loss: 0.866.. Test accuracy: 0.690\n",
      "Epoch 2/10.. Train loss: 0.953.. Test loss: 0.860.. Test accuracy: 0.688\n",
      "Epoch 2/10.. Train loss: 0.924.. Test loss: 0.895.. Test accuracy: 0.685\n",
      "Epoch 2/10.. Train loss: 0.899.. Test loss: 0.874.. Test accuracy: 0.685\n",
      "Epoch 2/10.. Train loss: 0.894.. Test loss: 0.884.. Test accuracy: 0.684\n",
      "Epoch 2/10.. Train loss: 0.948.. Test loss: 0.887.. Test accuracy: 0.671\n",
      "Epoch 2/10.. Train loss: 0.921.. Test loss: 0.857.. Test accuracy: 0.690\n",
      "Epoch 2/10.. Train loss: 0.906.. Test loss: 0.863.. Test accuracy: 0.685\n",
      "Epoch 2/10.. Train loss: 0.866.. Test loss: 0.869.. Test accuracy: 0.683\n",
      "Epoch 2/10.. Train loss: 0.994.. Test loss: 0.850.. Test accuracy: 0.690\n",
      "Epoch 2/10.. Train loss: 0.928.. Test loss: 0.865.. Test accuracy: 0.687\n",
      "Epoch 2/10.. Train loss: 0.922.. Test loss: 0.856.. Test accuracy: 0.682\n",
      "Epoch 2/10.. Train loss: 0.937.. Test loss: 0.877.. Test accuracy: 0.679\n",
      "Epoch 2/10.. Train loss: 0.932.. Test loss: 0.863.. Test accuracy: 0.685\n",
      "Epoch 2/10.. Train loss: 0.931.. Test loss: 0.874.. Test accuracy: 0.682\n",
      "Epoch 2/10.. Train loss: 0.979.. Test loss: 0.884.. Test accuracy: 0.674\n",
      "Epoch 2/10.. Train loss: 0.915.. Test loss: 0.871.. Test accuracy: 0.683\n",
      "Epoch 2/10.. Train loss: 0.963.. Test loss: 0.879.. Test accuracy: 0.680\n",
      "Epoch 3/10.. Train loss: 0.331.. Test loss: 0.891.. Test accuracy: 0.677\n",
      "Epoch 3/10.. Train loss: 0.854.. Test loss: 0.884.. Test accuracy: 0.684\n",
      "Epoch 3/10.. Train loss: 0.886.. Test loss: 0.865.. Test accuracy: 0.688\n",
      "Epoch 3/10.. Train loss: 0.944.. Test loss: 0.896.. Test accuracy: 0.677\n",
      "Epoch 3/10.. Train loss: 0.869.. Test loss: 0.873.. Test accuracy: 0.688\n",
      "Epoch 3/10.. Train loss: 0.877.. Test loss: 0.872.. Test accuracy: 0.682\n",
      "Epoch 3/10.. Train loss: 0.849.. Test loss: 0.886.. Test accuracy: 0.683\n",
      "Epoch 3/10.. Train loss: 0.913.. Test loss: 0.894.. Test accuracy: 0.682\n",
      "Epoch 3/10.. Train loss: 0.939.. Test loss: 0.881.. Test accuracy: 0.679\n",
      "Epoch 3/10.. Train loss: 0.865.. Test loss: 0.869.. Test accuracy: 0.687\n",
      "Epoch 3/10.. Train loss: 0.964.. Test loss: 0.856.. Test accuracy: 0.689\n",
      "Epoch 3/10.. Train loss: 0.882.. Test loss: 0.872.. Test accuracy: 0.683\n",
      "Epoch 3/10.. Train loss: 0.971.. Test loss: 0.862.. Test accuracy: 0.692\n",
      "Epoch 3/10.. Train loss: 0.910.. Test loss: 0.853.. Test accuracy: 0.690\n",
      "Epoch 3/10.. Train loss: 0.912.. Test loss: 0.853.. Test accuracy: 0.694\n",
      "Epoch 3/10.. Train loss: 0.860.. Test loss: 0.854.. Test accuracy: 0.690\n",
      "Epoch 3/10.. Train loss: 0.957.. Test loss: 0.859.. Test accuracy: 0.694\n",
      "Epoch 3/10.. Train loss: 0.856.. Test loss: 0.889.. Test accuracy: 0.671\n",
      "Epoch 3/10.. Train loss: 0.905.. Test loss: 0.856.. Test accuracy: 0.693\n",
      "Epoch 3/10.. Train loss: 0.873.. Test loss: 0.868.. Test accuracy: 0.686\n",
      "Epoch 3/10.. Train loss: 0.906.. Test loss: 0.848.. Test accuracy: 0.693\n",
      "Epoch 3/10.. Train loss: 0.836.. Test loss: 0.864.. Test accuracy: 0.684\n",
      "Epoch 3/10.. Train loss: 0.827.. Test loss: 0.878.. Test accuracy: 0.687\n",
      "Epoch 3/10.. Train loss: 0.875.. Test loss: 0.852.. Test accuracy: 0.695\n",
      "Epoch 3/10.. Train loss: 0.838.. Test loss: 0.841.. Test accuracy: 0.694\n",
      "Epoch 3/10.. Train loss: 0.827.. Test loss: 0.850.. Test accuracy: 0.693\n",
      "Epoch 3/10.. Train loss: 0.909.. Test loss: 0.864.. Test accuracy: 0.687\n",
      "Epoch 3/10.. Train loss: 0.873.. Test loss: 0.862.. Test accuracy: 0.689\n",
      "Epoch 3/10.. Train loss: 0.946.. Test loss: 0.897.. Test accuracy: 0.675\n",
      "Epoch 3/10.. Train loss: 0.955.. Test loss: 0.877.. Test accuracy: 0.678\n",
      "Epoch 3/10.. Train loss: 0.940.. Test loss: 0.889.. Test accuracy: 0.676\n",
      "Epoch 3/10.. Train loss: 0.899.. Test loss: 0.862.. Test accuracy: 0.684\n",
      "Epoch 3/10.. Train loss: 0.927.. Test loss: 0.861.. Test accuracy: 0.682\n",
      "Epoch 3/10.. Train loss: 0.899.. Test loss: 0.876.. Test accuracy: 0.681\n",
      "Epoch 3/10.. Train loss: 0.924.. Test loss: 0.858.. Test accuracy: 0.689\n",
      "Epoch 3/10.. Train loss: 0.872.. Test loss: 0.864.. Test accuracy: 0.685\n",
      "Epoch 3/10.. Train loss: 0.818.. Test loss: 0.874.. Test accuracy: 0.681\n",
      "Epoch 3/10.. Train loss: 0.903.. Test loss: 0.868.. Test accuracy: 0.686\n",
      "Epoch 3/10.. Train loss: 0.886.. Test loss: 0.880.. Test accuracy: 0.679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10.. Train loss: 0.859.. Test loss: 0.889.. Test accuracy: 0.679\n",
      "Epoch 3/10.. Train loss: 0.887.. Test loss: 0.861.. Test accuracy: 0.681\n",
      "Epoch 3/10.. Train loss: 0.836.. Test loss: 0.856.. Test accuracy: 0.691\n",
      "Epoch 3/10.. Train loss: 0.855.. Test loss: 0.870.. Test accuracy: 0.683\n",
      "Epoch 3/10.. Train loss: 0.827.. Test loss: 0.859.. Test accuracy: 0.691\n",
      "Epoch 3/10.. Train loss: 0.922.. Test loss: 0.848.. Test accuracy: 0.693\n",
      "Epoch 3/10.. Train loss: 0.922.. Test loss: 0.860.. Test accuracy: 0.686\n",
      "Epoch 3/10.. Train loss: 0.948.. Test loss: 0.857.. Test accuracy: 0.687\n",
      "Epoch 3/10.. Train loss: 0.865.. Test loss: 0.867.. Test accuracy: 0.682\n",
      "Epoch 3/10.. Train loss: 0.802.. Test loss: 0.848.. Test accuracy: 0.692\n",
      "Epoch 3/10.. Train loss: 0.851.. Test loss: 0.860.. Test accuracy: 0.686\n",
      "Epoch 3/10.. Train loss: 0.912.. Test loss: 0.837.. Test accuracy: 0.695\n",
      "Epoch 3/10.. Train loss: 0.903.. Test loss: 0.863.. Test accuracy: 0.686\n",
      "Epoch 3/10.. Train loss: 0.845.. Test loss: 0.891.. Test accuracy: 0.678\n",
      "Epoch 3/10.. Train loss: 0.877.. Test loss: 0.871.. Test accuracy: 0.689\n",
      "Epoch 3/10.. Train loss: 0.922.. Test loss: 0.872.. Test accuracy: 0.681\n",
      "Epoch 3/10.. Train loss: 0.794.. Test loss: 0.837.. Test accuracy: 0.695\n",
      "Epoch 3/10.. Train loss: 0.872.. Test loss: 0.859.. Test accuracy: 0.688\n",
      "Epoch 3/10.. Train loss: 0.855.. Test loss: 0.854.. Test accuracy: 0.688\n",
      "Epoch 3/10.. Train loss: 0.914.. Test loss: 0.866.. Test accuracy: 0.689\n",
      "Epoch 3/10.. Train loss: 0.945.. Test loss: 0.867.. Test accuracy: 0.686\n",
      "Epoch 3/10.. Train loss: 0.919.. Test loss: 0.867.. Test accuracy: 0.688\n",
      "Epoch 3/10.. Train loss: 0.884.. Test loss: 0.889.. Test accuracy: 0.686\n",
      "Epoch 3/10.. Train loss: 0.903.. Test loss: 0.855.. Test accuracy: 0.688\n",
      "Epoch 3/10.. Train loss: 0.894.. Test loss: 0.849.. Test accuracy: 0.694\n",
      "Epoch 3/10.. Train loss: 0.821.. Test loss: 0.836.. Test accuracy: 0.694\n",
      "Epoch 3/10.. Train loss: 0.823.. Test loss: 0.850.. Test accuracy: 0.692\n",
      "Epoch 3/10.. Train loss: 0.911.. Test loss: 0.853.. Test accuracy: 0.693\n",
      "Epoch 3/10.. Train loss: 0.880.. Test loss: 0.862.. Test accuracy: 0.695\n",
      "Epoch 3/10.. Train loss: 0.902.. Test loss: 0.892.. Test accuracy: 0.674\n",
      "Epoch 3/10.. Train loss: 0.868.. Test loss: 0.906.. Test accuracy: 0.664\n",
      "Epoch 3/10.. Train loss: 0.922.. Test loss: 0.902.. Test accuracy: 0.673\n",
      "Epoch 3/10.. Train loss: 0.871.. Test loss: 0.889.. Test accuracy: 0.672\n",
      "Epoch 3/10.. Train loss: 0.998.. Test loss: 0.875.. Test accuracy: 0.680\n",
      "Epoch 3/10.. Train loss: 0.895.. Test loss: 0.833.. Test accuracy: 0.699\n",
      "Epoch 3/10.. Train loss: 0.883.. Test loss: 0.882.. Test accuracy: 0.687\n",
      "Epoch 3/10.. Train loss: 0.842.. Test loss: 0.855.. Test accuracy: 0.692\n",
      "Epoch 3/10.. Train loss: 0.872.. Test loss: 0.869.. Test accuracy: 0.686\n",
      "Epoch 3/10.. Train loss: 0.932.. Test loss: 0.858.. Test accuracy: 0.692\n",
      "Epoch 3/10.. Train loss: 0.845.. Test loss: 0.864.. Test accuracy: 0.686\n",
      "Epoch 3/10.. Train loss: 0.874.. Test loss: 0.865.. Test accuracy: 0.689\n",
      "Epoch 3/10.. Train loss: 0.793.. Test loss: 0.881.. Test accuracy: 0.680\n",
      "Epoch 3/10.. Train loss: 0.931.. Test loss: 0.846.. Test accuracy: 0.692\n",
      "Epoch 3/10.. Train loss: 0.829.. Test loss: 0.872.. Test accuracy: 0.686\n",
      "Epoch 3/10.. Train loss: 0.792.. Test loss: 0.856.. Test accuracy: 0.692\n",
      "Epoch 3/10.. Train loss: 0.832.. Test loss: 0.853.. Test accuracy: 0.692\n",
      "Epoch 3/10.. Train loss: 0.879.. Test loss: 0.859.. Test accuracy: 0.684\n",
      "Epoch 3/10.. Train loss: 0.854.. Test loss: 0.840.. Test accuracy: 0.696\n",
      "Epoch 3/10.. Train loss: 0.825.. Test loss: 0.851.. Test accuracy: 0.697\n",
      "Epoch 3/10.. Train loss: 0.926.. Test loss: 0.866.. Test accuracy: 0.680\n",
      "Epoch 3/10.. Train loss: 0.839.. Test loss: 0.852.. Test accuracy: 0.688\n",
      "Epoch 3/10.. Train loss: 0.897.. Test loss: 0.847.. Test accuracy: 0.690\n",
      "Epoch 3/10.. Train loss: 0.838.. Test loss: 0.843.. Test accuracy: 0.688\n",
      "Epoch 3/10.. Train loss: 0.924.. Test loss: 0.847.. Test accuracy: 0.691\n",
      "Epoch 3/10.. Train loss: 0.888.. Test loss: 0.849.. Test accuracy: 0.696\n",
      "Epoch 4/10.. Train loss: 0.474.. Test loss: 0.842.. Test accuracy: 0.693\n",
      "Epoch 4/10.. Train loss: 0.860.. Test loss: 0.858.. Test accuracy: 0.691\n",
      "Epoch 4/10.. Train loss: 0.883.. Test loss: 0.847.. Test accuracy: 0.694\n",
      "Epoch 4/10.. Train loss: 0.841.. Test loss: 0.856.. Test accuracy: 0.691\n",
      "Epoch 4/10.. Train loss: 0.890.. Test loss: 0.873.. Test accuracy: 0.686\n",
      "Epoch 4/10.. Train loss: 0.848.. Test loss: 0.844.. Test accuracy: 0.691\n",
      "Epoch 4/10.. Train loss: 0.834.. Test loss: 0.860.. Test accuracy: 0.692\n",
      "Epoch 4/10.. Train loss: 0.791.. Test loss: 0.874.. Test accuracy: 0.687\n",
      "Epoch 4/10.. Train loss: 0.872.. Test loss: 0.847.. Test accuracy: 0.696\n",
      "Epoch 4/10.. Train loss: 0.786.. Test loss: 0.844.. Test accuracy: 0.695\n",
      "Epoch 4/10.. Train loss: 0.909.. Test loss: 0.859.. Test accuracy: 0.687\n",
      "Epoch 4/10.. Train loss: 0.861.. Test loss: 0.855.. Test accuracy: 0.687\n",
      "Epoch 4/10.. Train loss: 0.932.. Test loss: 0.841.. Test accuracy: 0.696\n",
      "Epoch 4/10.. Train loss: 0.903.. Test loss: 0.846.. Test accuracy: 0.693\n",
      "Epoch 4/10.. Train loss: 0.835.. Test loss: 0.851.. Test accuracy: 0.690\n",
      "Epoch 4/10.. Train loss: 0.881.. Test loss: 0.838.. Test accuracy: 0.697\n",
      "Epoch 4/10.. Train loss: 0.900.. Test loss: 0.840.. Test accuracy: 0.692\n",
      "Epoch 4/10.. Train loss: 0.807.. Test loss: 0.854.. Test accuracy: 0.698\n",
      "Epoch 4/10.. Train loss: 0.922.. Test loss: 0.835.. Test accuracy: 0.697\n",
      "Epoch 4/10.. Train loss: 0.819.. Test loss: 0.843.. Test accuracy: 0.697\n",
      "Epoch 4/10.. Train loss: 0.825.. Test loss: 0.837.. Test accuracy: 0.692\n",
      "Epoch 4/10.. Train loss: 0.843.. Test loss: 0.845.. Test accuracy: 0.695\n",
      "Epoch 4/10.. Train loss: 0.782.. Test loss: 0.850.. Test accuracy: 0.693\n",
      "Epoch 4/10.. Train loss: 0.895.. Test loss: 0.841.. Test accuracy: 0.699\n",
      "Epoch 4/10.. Train loss: 0.777.. Test loss: 0.854.. Test accuracy: 0.689\n",
      "Epoch 4/10.. Train loss: 0.896.. Test loss: 0.854.. Test accuracy: 0.689\n",
      "Epoch 4/10.. Train loss: 0.925.. Test loss: 0.836.. Test accuracy: 0.695\n",
      "Epoch 4/10.. Train loss: 0.887.. Test loss: 0.839.. Test accuracy: 0.691\n",
      "Epoch 4/10.. Train loss: 0.841.. Test loss: 0.849.. Test accuracy: 0.689\n",
      "Epoch 4/10.. Train loss: 0.817.. Test loss: 0.837.. Test accuracy: 0.693\n",
      "Epoch 4/10.. Train loss: 0.948.. Test loss: 0.830.. Test accuracy: 0.700\n",
      "Epoch 4/10.. Train loss: 0.924.. Test loss: 0.830.. Test accuracy: 0.699\n",
      "Epoch 4/10.. Train loss: 0.879.. Test loss: 0.835.. Test accuracy: 0.694\n",
      "Epoch 4/10.. Train loss: 0.852.. Test loss: 0.824.. Test accuracy: 0.702\n",
      "Epoch 4/10.. Train loss: 0.819.. Test loss: 0.829.. Test accuracy: 0.701\n",
      "Epoch 4/10.. Train loss: 0.860.. Test loss: 0.832.. Test accuracy: 0.701\n",
      "Epoch 4/10.. Train loss: 0.866.. Test loss: 0.848.. Test accuracy: 0.693\n",
      "Epoch 4/10.. Train loss: 0.842.. Test loss: 0.822.. Test accuracy: 0.699\n",
      "Epoch 4/10.. Train loss: 0.913.. Test loss: 0.823.. Test accuracy: 0.701\n",
      "Epoch 4/10.. Train loss: 0.891.. Test loss: 0.827.. Test accuracy: 0.700\n",
      "Epoch 4/10.. Train loss: 0.797.. Test loss: 0.818.. Test accuracy: 0.698\n",
      "Epoch 4/10.. Train loss: 0.824.. Test loss: 0.825.. Test accuracy: 0.700\n",
      "Epoch 4/10.. Train loss: 0.874.. Test loss: 0.841.. Test accuracy: 0.693\n",
      "Epoch 4/10.. Train loss: 0.855.. Test loss: 0.873.. Test accuracy: 0.683\n",
      "Epoch 4/10.. Train loss: 0.832.. Test loss: 0.844.. Test accuracy: 0.687\n",
      "Epoch 4/10.. Train loss: 0.813.. Test loss: 0.830.. Test accuracy: 0.697\n",
      "Epoch 4/10.. Train loss: 0.842.. Test loss: 0.837.. Test accuracy: 0.695\n",
      "Epoch 4/10.. Train loss: 0.895.. Test loss: 0.841.. Test accuracy: 0.693\n",
      "Epoch 4/10.. Train loss: 0.863.. Test loss: 0.833.. Test accuracy: 0.697\n",
      "Epoch 4/10.. Train loss: 0.948.. Test loss: 0.836.. Test accuracy: 0.695\n",
      "Epoch 4/10.. Train loss: 0.825.. Test loss: 0.835.. Test accuracy: 0.689\n",
      "Epoch 4/10.. Train loss: 0.852.. Test loss: 0.825.. Test accuracy: 0.698\n",
      "Epoch 4/10.. Train loss: 0.787.. Test loss: 0.839.. Test accuracy: 0.689\n",
      "Epoch 4/10.. Train loss: 0.874.. Test loss: 0.825.. Test accuracy: 0.700\n",
      "Epoch 4/10.. Train loss: 0.864.. Test loss: 0.835.. Test accuracy: 0.697\n",
      "Epoch 4/10.. Train loss: 0.844.. Test loss: 0.858.. Test accuracy: 0.689\n",
      "Epoch 4/10.. Train loss: 0.834.. Test loss: 0.823.. Test accuracy: 0.697\n",
      "Epoch 4/10.. Train loss: 0.875.. Test loss: 0.864.. Test accuracy: 0.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10.. Train loss: 0.830.. Test loss: 0.829.. Test accuracy: 0.699\n",
      "Epoch 4/10.. Train loss: 0.861.. Test loss: 0.839.. Test accuracy: 0.692\n",
      "Epoch 4/10.. Train loss: 0.815.. Test loss: 0.826.. Test accuracy: 0.700\n",
      "Epoch 4/10.. Train loss: 0.860.. Test loss: 0.842.. Test accuracy: 0.689\n",
      "Epoch 4/10.. Train loss: 0.807.. Test loss: 0.834.. Test accuracy: 0.695\n",
      "Epoch 4/10.. Train loss: 0.798.. Test loss: 0.841.. Test accuracy: 0.694\n",
      "Epoch 4/10.. Train loss: 0.878.. Test loss: 0.824.. Test accuracy: 0.696\n",
      "Epoch 4/10.. Train loss: 0.874.. Test loss: 0.818.. Test accuracy: 0.699\n",
      "Epoch 4/10.. Train loss: 0.836.. Test loss: 0.865.. Test accuracy: 0.683\n",
      "Epoch 4/10.. Train loss: 0.835.. Test loss: 0.837.. Test accuracy: 0.697\n",
      "Epoch 4/10.. Train loss: 0.835.. Test loss: 0.819.. Test accuracy: 0.695\n",
      "Epoch 4/10.. Train loss: 0.857.. Test loss: 0.831.. Test accuracy: 0.691\n",
      "Epoch 4/10.. Train loss: 0.928.. Test loss: 0.805.. Test accuracy: 0.703\n",
      "Epoch 4/10.. Train loss: 0.736.. Test loss: 0.818.. Test accuracy: 0.702\n",
      "Epoch 4/10.. Train loss: 0.796.. Test loss: 0.832.. Test accuracy: 0.696\n",
      "Epoch 4/10.. Train loss: 0.900.. Test loss: 0.829.. Test accuracy: 0.696\n",
      "Epoch 4/10.. Train loss: 0.910.. Test loss: 0.830.. Test accuracy: 0.693\n",
      "Epoch 4/10.. Train loss: 0.896.. Test loss: 0.822.. Test accuracy: 0.698\n",
      "Epoch 4/10.. Train loss: 0.860.. Test loss: 0.849.. Test accuracy: 0.687\n",
      "Epoch 4/10.. Train loss: 0.818.. Test loss: 0.829.. Test accuracy: 0.700\n",
      "Epoch 4/10.. Train loss: 0.851.. Test loss: 0.817.. Test accuracy: 0.700\n",
      "Epoch 4/10.. Train loss: 0.847.. Test loss: 0.846.. Test accuracy: 0.691\n",
      "Epoch 4/10.. Train loss: 0.873.. Test loss: 0.826.. Test accuracy: 0.698\n",
      "Epoch 4/10.. Train loss: 0.906.. Test loss: 0.833.. Test accuracy: 0.697\n",
      "Epoch 4/10.. Train loss: 0.897.. Test loss: 0.824.. Test accuracy: 0.698\n",
      "Epoch 4/10.. Train loss: 0.878.. Test loss: 0.830.. Test accuracy: 0.696\n",
      "Epoch 4/10.. Train loss: 0.809.. Test loss: 0.826.. Test accuracy: 0.698\n",
      "Epoch 4/10.. Train loss: 0.825.. Test loss: 0.814.. Test accuracy: 0.705\n",
      "Epoch 4/10.. Train loss: 0.869.. Test loss: 0.823.. Test accuracy: 0.696\n",
      "Epoch 4/10.. Train loss: 0.863.. Test loss: 0.809.. Test accuracy: 0.702\n",
      "Epoch 4/10.. Train loss: 0.807.. Test loss: 0.816.. Test accuracy: 0.701\n",
      "Epoch 4/10.. Train loss: 0.843.. Test loss: 0.826.. Test accuracy: 0.701\n",
      "Epoch 4/10.. Train loss: 0.830.. Test loss: 0.822.. Test accuracy: 0.700\n",
      "Epoch 4/10.. Train loss: 0.931.. Test loss: 0.819.. Test accuracy: 0.702\n",
      "Epoch 4/10.. Train loss: 0.839.. Test loss: 0.834.. Test accuracy: 0.700\n",
      "Epoch 4/10.. Train loss: 0.873.. Test loss: 0.829.. Test accuracy: 0.696\n",
      "Epoch 5/10.. Train loss: 0.648.. Test loss: 0.832.. Test accuracy: 0.697\n",
      "Epoch 5/10.. Train loss: 0.865.. Test loss: 0.839.. Test accuracy: 0.696\n",
      "Epoch 5/10.. Train loss: 0.835.. Test loss: 0.809.. Test accuracy: 0.707\n",
      "Epoch 5/10.. Train loss: 0.812.. Test loss: 0.828.. Test accuracy: 0.699\n",
      "Epoch 5/10.. Train loss: 0.853.. Test loss: 0.817.. Test accuracy: 0.702\n",
      "Epoch 5/10.. Train loss: 0.829.. Test loss: 0.812.. Test accuracy: 0.703\n",
      "Epoch 5/10.. Train loss: 0.795.. Test loss: 0.827.. Test accuracy: 0.699\n",
      "Epoch 5/10.. Train loss: 0.815.. Test loss: 0.829.. Test accuracy: 0.700\n",
      "Epoch 5/10.. Train loss: 0.742.. Test loss: 0.835.. Test accuracy: 0.697\n",
      "Epoch 5/10.. Train loss: 0.876.. Test loss: 0.832.. Test accuracy: 0.692\n",
      "Epoch 5/10.. Train loss: 0.772.. Test loss: 0.805.. Test accuracy: 0.707\n",
      "Epoch 5/10.. Train loss: 0.797.. Test loss: 0.817.. Test accuracy: 0.699\n",
      "Epoch 5/10.. Train loss: 0.842.. Test loss: 0.816.. Test accuracy: 0.701\n",
      "Epoch 5/10.. Train loss: 0.755.. Test loss: 0.826.. Test accuracy: 0.696\n",
      "Epoch 5/10.. Train loss: 0.838.. Test loss: 0.824.. Test accuracy: 0.697\n",
      "Epoch 5/10.. Train loss: 0.813.. Test loss: 0.819.. Test accuracy: 0.701\n",
      "Epoch 5/10.. Train loss: 0.858.. Test loss: 0.827.. Test accuracy: 0.695\n",
      "Epoch 5/10.. Train loss: 0.837.. Test loss: 0.830.. Test accuracy: 0.697\n",
      "Epoch 5/10.. Train loss: 0.768.. Test loss: 0.856.. Test accuracy: 0.686\n",
      "Epoch 5/10.. Train loss: 0.827.. Test loss: 0.829.. Test accuracy: 0.694\n",
      "Epoch 5/10.. Train loss: 0.858.. Test loss: 0.846.. Test accuracy: 0.693\n",
      "Epoch 5/10.. Train loss: 0.813.. Test loss: 0.802.. Test accuracy: 0.704\n",
      "Epoch 5/10.. Train loss: 0.788.. Test loss: 0.823.. Test accuracy: 0.696\n",
      "Epoch 5/10.. Train loss: 0.858.. Test loss: 0.855.. Test accuracy: 0.690\n",
      "Epoch 5/10.. Train loss: 0.753.. Test loss: 0.817.. Test accuracy: 0.707\n",
      "Epoch 5/10.. Train loss: 0.831.. Test loss: 0.828.. Test accuracy: 0.695\n",
      "Epoch 5/10.. Train loss: 0.840.. Test loss: 0.837.. Test accuracy: 0.693\n",
      "Epoch 5/10.. Train loss: 0.890.. Test loss: 0.861.. Test accuracy: 0.688\n",
      "Epoch 5/10.. Train loss: 0.877.. Test loss: 0.856.. Test accuracy: 0.687\n",
      "Epoch 5/10.. Train loss: 0.840.. Test loss: 0.830.. Test accuracy: 0.697\n",
      "Epoch 5/10.. Train loss: 0.857.. Test loss: 0.823.. Test accuracy: 0.699\n",
      "Epoch 5/10.. Train loss: 0.864.. Test loss: 0.838.. Test accuracy: 0.696\n",
      "Epoch 5/10.. Train loss: 0.848.. Test loss: 0.832.. Test accuracy: 0.699\n",
      "Epoch 5/10.. Train loss: 0.802.. Test loss: 0.831.. Test accuracy: 0.695\n",
      "Epoch 5/10.. Train loss: 0.867.. Test loss: 0.823.. Test accuracy: 0.700\n",
      "Epoch 5/10.. Train loss: 0.851.. Test loss: 0.839.. Test accuracy: 0.697\n",
      "Epoch 5/10.. Train loss: 0.899.. Test loss: 0.838.. Test accuracy: 0.699\n",
      "Epoch 5/10.. Train loss: 0.846.. Test loss: 0.822.. Test accuracy: 0.703\n",
      "Epoch 5/10.. Train loss: 0.902.. Test loss: 0.836.. Test accuracy: 0.697\n",
      "Epoch 5/10.. Train loss: 0.860.. Test loss: 0.836.. Test accuracy: 0.700\n",
      "Epoch 5/10.. Train loss: 0.864.. Test loss: 0.825.. Test accuracy: 0.697\n",
      "Epoch 5/10.. Train loss: 0.856.. Test loss: 0.829.. Test accuracy: 0.700\n",
      "Epoch 5/10.. Train loss: 0.795.. Test loss: 0.842.. Test accuracy: 0.701\n",
      "Epoch 5/10.. Train loss: 0.814.. Test loss: 0.827.. Test accuracy: 0.705\n",
      "Epoch 5/10.. Train loss: 0.832.. Test loss: 0.835.. Test accuracy: 0.703\n",
      "Epoch 5/10.. Train loss: 0.923.. Test loss: 0.844.. Test accuracy: 0.694\n",
      "Epoch 5/10.. Train loss: 0.864.. Test loss: 0.813.. Test accuracy: 0.705\n",
      "Epoch 5/10.. Train loss: 0.854.. Test loss: 0.824.. Test accuracy: 0.698\n",
      "Epoch 5/10.. Train loss: 0.832.. Test loss: 0.826.. Test accuracy: 0.695\n",
      "Epoch 5/10.. Train loss: 0.843.. Test loss: 0.806.. Test accuracy: 0.704\n",
      "Epoch 5/10.. Train loss: 0.886.. Test loss: 0.817.. Test accuracy: 0.700\n",
      "Epoch 5/10.. Train loss: 0.847.. Test loss: 0.803.. Test accuracy: 0.707\n",
      "Epoch 5/10.. Train loss: 0.816.. Test loss: 0.820.. Test accuracy: 0.698\n",
      "Epoch 5/10.. Train loss: 0.849.. Test loss: 0.841.. Test accuracy: 0.690\n",
      "Epoch 5/10.. Train loss: 0.837.. Test loss: 0.826.. Test accuracy: 0.697\n",
      "Epoch 5/10.. Train loss: 0.807.. Test loss: 0.816.. Test accuracy: 0.700\n",
      "Epoch 5/10.. Train loss: 0.739.. Test loss: 0.813.. Test accuracy: 0.708\n",
      "Epoch 5/10.. Train loss: 0.835.. Test loss: 0.822.. Test accuracy: 0.703\n",
      "Epoch 5/10.. Train loss: 0.797.. Test loss: 0.824.. Test accuracy: 0.701\n",
      "Epoch 5/10.. Train loss: 0.789.. Test loss: 0.814.. Test accuracy: 0.705\n",
      "Epoch 5/10.. Train loss: 0.822.. Test loss: 0.830.. Test accuracy: 0.704\n",
      "Epoch 5/10.. Train loss: 0.867.. Test loss: 0.815.. Test accuracy: 0.704\n",
      "Epoch 5/10.. Train loss: 0.875.. Test loss: 0.826.. Test accuracy: 0.700\n",
      "Epoch 5/10.. Train loss: 0.832.. Test loss: 0.820.. Test accuracy: 0.701\n",
      "Epoch 5/10.. Train loss: 0.801.. Test loss: 0.820.. Test accuracy: 0.702\n",
      "Epoch 5/10.. Train loss: 0.875.. Test loss: 0.818.. Test accuracy: 0.700\n",
      "Epoch 5/10.. Train loss: 0.809.. Test loss: 0.825.. Test accuracy: 0.703\n",
      "Epoch 5/10.. Train loss: 0.841.. Test loss: 0.805.. Test accuracy: 0.711\n",
      "Epoch 5/10.. Train loss: 0.774.. Test loss: 0.816.. Test accuracy: 0.701\n",
      "Epoch 5/10.. Train loss: 0.869.. Test loss: 0.851.. Test accuracy: 0.693\n",
      "Epoch 5/10.. Train loss: 0.776.. Test loss: 0.851.. Test accuracy: 0.693\n",
      "Epoch 5/10.. Train loss: 0.819.. Test loss: 0.829.. Test accuracy: 0.702\n",
      "Epoch 5/10.. Train loss: 0.913.. Test loss: 0.834.. Test accuracy: 0.693\n",
      "Epoch 5/10.. Train loss: 0.820.. Test loss: 0.801.. Test accuracy: 0.707\n",
      "Epoch 5/10.. Train loss: 0.802.. Test loss: 0.835.. Test accuracy: 0.702\n",
      "Epoch 5/10.. Train loss: 0.868.. Test loss: 0.825.. Test accuracy: 0.697\n",
      "Epoch 5/10.. Train loss: 0.846.. Test loss: 0.826.. Test accuracy: 0.695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10.. Train loss: 0.843.. Test loss: 0.815.. Test accuracy: 0.698\n",
      "Epoch 5/10.. Train loss: 0.818.. Test loss: 0.838.. Test accuracy: 0.691\n",
      "Epoch 5/10.. Train loss: 0.802.. Test loss: 0.822.. Test accuracy: 0.704\n",
      "Epoch 5/10.. Train loss: 0.880.. Test loss: 0.827.. Test accuracy: 0.693\n",
      "Epoch 5/10.. Train loss: 0.853.. Test loss: 0.809.. Test accuracy: 0.703\n",
      "Epoch 5/10.. Train loss: 0.839.. Test loss: 0.813.. Test accuracy: 0.702\n",
      "Epoch 5/10.. Train loss: 0.839.. Test loss: 0.810.. Test accuracy: 0.702\n",
      "Epoch 5/10.. Train loss: 0.847.. Test loss: 0.819.. Test accuracy: 0.698\n",
      "Epoch 5/10.. Train loss: 0.837.. Test loss: 0.817.. Test accuracy: 0.703\n",
      "Epoch 5/10.. Train loss: 0.960.. Test loss: 0.828.. Test accuracy: 0.692\n",
      "Epoch 5/10.. Train loss: 0.776.. Test loss: 0.810.. Test accuracy: 0.704\n",
      "Epoch 5/10.. Train loss: 0.802.. Test loss: 0.814.. Test accuracy: 0.708\n",
      "Epoch 5/10.. Train loss: 0.896.. Test loss: 0.806.. Test accuracy: 0.706\n",
      "Epoch 5/10.. Train loss: 0.846.. Test loss: 0.818.. Test accuracy: 0.702\n",
      "Epoch 5/10.. Train loss: 0.844.. Test loss: 0.811.. Test accuracy: 0.706\n",
      "Epoch 5/10.. Train loss: 0.840.. Test loss: 0.809.. Test accuracy: 0.703\n",
      "Epoch 5/10.. Train loss: 0.866.. Test loss: 0.815.. Test accuracy: 0.702\n",
      "Epoch 6/10.. Train loss: 0.752.. Test loss: 0.814.. Test accuracy: 0.702\n",
      "Epoch 6/10.. Train loss: 0.757.. Test loss: 0.809.. Test accuracy: 0.703\n",
      "Epoch 6/10.. Train loss: 0.808.. Test loss: 0.817.. Test accuracy: 0.708\n",
      "Epoch 6/10.. Train loss: 0.730.. Test loss: 0.816.. Test accuracy: 0.709\n",
      "Epoch 6/10.. Train loss: 0.779.. Test loss: 0.826.. Test accuracy: 0.701\n",
      "Epoch 6/10.. Train loss: 0.771.. Test loss: 0.819.. Test accuracy: 0.706\n",
      "Epoch 6/10.. Train loss: 0.814.. Test loss: 0.842.. Test accuracy: 0.691\n",
      "Epoch 6/10.. Train loss: 0.900.. Test loss: 0.829.. Test accuracy: 0.701\n",
      "Epoch 6/10.. Train loss: 0.810.. Test loss: 0.816.. Test accuracy: 0.702\n",
      "Epoch 6/10.. Train loss: 0.827.. Test loss: 0.823.. Test accuracy: 0.704\n",
      "Epoch 6/10.. Train loss: 0.807.. Test loss: 0.808.. Test accuracy: 0.708\n",
      "Epoch 6/10.. Train loss: 0.831.. Test loss: 0.804.. Test accuracy: 0.706\n",
      "Epoch 6/10.. Train loss: 0.808.. Test loss: 0.810.. Test accuracy: 0.706\n",
      "Epoch 6/10.. Train loss: 0.882.. Test loss: 0.812.. Test accuracy: 0.703\n",
      "Epoch 6/10.. Train loss: 0.870.. Test loss: 0.823.. Test accuracy: 0.698\n",
      "Epoch 6/10.. Train loss: 0.823.. Test loss: 0.825.. Test accuracy: 0.697\n",
      "Epoch 6/10.. Train loss: 0.788.. Test loss: 0.814.. Test accuracy: 0.703\n",
      "Epoch 6/10.. Train loss: 0.809.. Test loss: 0.824.. Test accuracy: 0.705\n",
      "Epoch 6/10.. Train loss: 0.843.. Test loss: 0.836.. Test accuracy: 0.698\n",
      "Epoch 6/10.. Train loss: 0.843.. Test loss: 0.817.. Test accuracy: 0.702\n",
      "Epoch 6/10.. Train loss: 0.785.. Test loss: 0.802.. Test accuracy: 0.711\n",
      "Epoch 6/10.. Train loss: 0.862.. Test loss: 0.809.. Test accuracy: 0.706\n",
      "Epoch 6/10.. Train loss: 0.839.. Test loss: 0.818.. Test accuracy: 0.704\n",
      "Epoch 6/10.. Train loss: 0.773.. Test loss: 0.814.. Test accuracy: 0.701\n",
      "Epoch 6/10.. Train loss: 0.781.. Test loss: 0.805.. Test accuracy: 0.705\n",
      "Epoch 6/10.. Train loss: 0.820.. Test loss: 0.817.. Test accuracy: 0.697\n",
      "Epoch 6/10.. Train loss: 0.806.. Test loss: 0.798.. Test accuracy: 0.708\n",
      "Epoch 6/10.. Train loss: 0.796.. Test loss: 0.828.. Test accuracy: 0.699\n",
      "Epoch 6/10.. Train loss: 0.826.. Test loss: 0.831.. Test accuracy: 0.699\n",
      "Epoch 6/10.. Train loss: 0.880.. Test loss: 0.802.. Test accuracy: 0.705\n",
      "Epoch 6/10.. Train loss: 0.776.. Test loss: 0.808.. Test accuracy: 0.707\n",
      "Epoch 6/10.. Train loss: 0.806.. Test loss: 0.806.. Test accuracy: 0.707\n",
      "Epoch 6/10.. Train loss: 0.863.. Test loss: 0.802.. Test accuracy: 0.707\n",
      "Epoch 6/10.. Train loss: 0.897.. Test loss: 0.807.. Test accuracy: 0.701\n",
      "Epoch 6/10.. Train loss: 0.878.. Test loss: 0.801.. Test accuracy: 0.707\n",
      "Epoch 6/10.. Train loss: 0.814.. Test loss: 0.802.. Test accuracy: 0.703\n",
      "Epoch 6/10.. Train loss: 0.859.. Test loss: 0.831.. Test accuracy: 0.697\n",
      "Epoch 6/10.. Train loss: 0.810.. Test loss: 0.803.. Test accuracy: 0.709\n",
      "Epoch 6/10.. Train loss: 0.878.. Test loss: 0.801.. Test accuracy: 0.705\n",
      "Epoch 6/10.. Train loss: 0.827.. Test loss: 0.824.. Test accuracy: 0.697\n",
      "Epoch 6/10.. Train loss: 0.838.. Test loss: 0.802.. Test accuracy: 0.702\n",
      "Epoch 6/10.. Train loss: 0.782.. Test loss: 0.840.. Test accuracy: 0.695\n",
      "Epoch 6/10.. Train loss: 0.770.. Test loss: 0.846.. Test accuracy: 0.691\n",
      "Epoch 6/10.. Train loss: 0.728.. Test loss: 0.827.. Test accuracy: 0.696\n",
      "Epoch 6/10.. Train loss: 0.856.. Test loss: 0.819.. Test accuracy: 0.703\n",
      "Epoch 6/10.. Train loss: 0.850.. Test loss: 0.800.. Test accuracy: 0.710\n",
      "Epoch 6/10.. Train loss: 0.847.. Test loss: 0.787.. Test accuracy: 0.714\n",
      "Epoch 6/10.. Train loss: 0.802.. Test loss: 0.802.. Test accuracy: 0.708\n",
      "Epoch 6/10.. Train loss: 0.908.. Test loss: 0.794.. Test accuracy: 0.707\n",
      "Epoch 6/10.. Train loss: 0.804.. Test loss: 0.786.. Test accuracy: 0.707\n",
      "Epoch 6/10.. Train loss: 0.823.. Test loss: 0.799.. Test accuracy: 0.707\n",
      "Epoch 6/10.. Train loss: 0.757.. Test loss: 0.796.. Test accuracy: 0.707\n",
      "Epoch 6/10.. Train loss: 0.768.. Test loss: 0.843.. Test accuracy: 0.690\n",
      "Epoch 6/10.. Train loss: 0.917.. Test loss: 0.824.. Test accuracy: 0.698\n",
      "Epoch 6/10.. Train loss: 0.884.. Test loss: 0.813.. Test accuracy: 0.699\n",
      "Epoch 6/10.. Train loss: 0.814.. Test loss: 0.810.. Test accuracy: 0.704\n",
      "Epoch 6/10.. Train loss: 0.758.. Test loss: 0.804.. Test accuracy: 0.706\n",
      "Epoch 6/10.. Train loss: 0.786.. Test loss: 0.803.. Test accuracy: 0.708\n",
      "Epoch 6/10.. Train loss: 0.812.. Test loss: 0.816.. Test accuracy: 0.703\n",
      "Epoch 6/10.. Train loss: 0.842.. Test loss: 0.806.. Test accuracy: 0.703\n",
      "Epoch 6/10.. Train loss: 0.782.. Test loss: 0.804.. Test accuracy: 0.708\n",
      "Epoch 6/10.. Train loss: 0.813.. Test loss: 0.797.. Test accuracy: 0.714\n",
      "Epoch 6/10.. Train loss: 0.787.. Test loss: 0.806.. Test accuracy: 0.709\n",
      "Epoch 6/10.. Train loss: 0.863.. Test loss: 0.807.. Test accuracy: 0.705\n",
      "Epoch 6/10.. Train loss: 0.839.. Test loss: 0.812.. Test accuracy: 0.708\n",
      "Epoch 6/10.. Train loss: 0.815.. Test loss: 0.829.. Test accuracy: 0.704\n",
      "Epoch 6/10.. Train loss: 0.826.. Test loss: 0.800.. Test accuracy: 0.710\n",
      "Epoch 6/10.. Train loss: 0.852.. Test loss: 0.811.. Test accuracy: 0.705\n",
      "Epoch 6/10.. Train loss: 0.862.. Test loss: 0.792.. Test accuracy: 0.711\n",
      "Epoch 6/10.. Train loss: 0.808.. Test loss: 0.790.. Test accuracy: 0.714\n",
      "Epoch 6/10.. Train loss: 0.829.. Test loss: 0.795.. Test accuracy: 0.710\n",
      "Epoch 6/10.. Train loss: 0.836.. Test loss: 0.798.. Test accuracy: 0.709\n",
      "Epoch 6/10.. Train loss: 0.775.. Test loss: 0.787.. Test accuracy: 0.715\n",
      "Epoch 6/10.. Train loss: 0.726.. Test loss: 0.820.. Test accuracy: 0.702\n",
      "Epoch 6/10.. Train loss: 0.845.. Test loss: 0.808.. Test accuracy: 0.705\n",
      "Epoch 6/10.. Train loss: 0.818.. Test loss: 0.816.. Test accuracy: 0.702\n",
      "Epoch 6/10.. Train loss: 0.824.. Test loss: 0.833.. Test accuracy: 0.702\n",
      "Epoch 6/10.. Train loss: 0.878.. Test loss: 0.813.. Test accuracy: 0.704\n",
      "Epoch 6/10.. Train loss: 0.783.. Test loss: 0.813.. Test accuracy: 0.703\n",
      "Epoch 6/10.. Train loss: 0.817.. Test loss: 0.803.. Test accuracy: 0.705\n",
      "Epoch 6/10.. Train loss: 0.747.. Test loss: 0.818.. Test accuracy: 0.699\n",
      "Epoch 6/10.. Train loss: 0.823.. Test loss: 0.818.. Test accuracy: 0.701\n",
      "Epoch 6/10.. Train loss: 0.855.. Test loss: 0.820.. Test accuracy: 0.698\n",
      "Epoch 6/10.. Train loss: 0.797.. Test loss: 0.806.. Test accuracy: 0.705\n",
      "Epoch 6/10.. Train loss: 0.768.. Test loss: 0.819.. Test accuracy: 0.701\n",
      "Epoch 6/10.. Train loss: 0.880.. Test loss: 0.805.. Test accuracy: 0.707\n",
      "Epoch 6/10.. Train loss: 0.888.. Test loss: 0.818.. Test accuracy: 0.706\n",
      "Epoch 6/10.. Train loss: 0.770.. Test loss: 0.817.. Test accuracy: 0.702\n",
      "Epoch 6/10.. Train loss: 0.891.. Test loss: 0.797.. Test accuracy: 0.711\n",
      "Epoch 6/10.. Train loss: 0.770.. Test loss: 0.814.. Test accuracy: 0.705\n",
      "Epoch 6/10.. Train loss: 0.881.. Test loss: 0.832.. Test accuracy: 0.700\n",
      "Epoch 6/10.. Train loss: 0.795.. Test loss: 0.799.. Test accuracy: 0.709\n",
      "Epoch 6/10.. Train loss: 0.843.. Test loss: 0.809.. Test accuracy: 0.703\n",
      "Epoch 7/10.. Train loss: 0.163.. Test loss: 0.822.. Test accuracy: 0.695\n",
      "Epoch 7/10.. Train loss: 0.703.. Test loss: 0.807.. Test accuracy: 0.705\n",
      "Epoch 7/10.. Train loss: 0.844.. Test loss: 0.827.. Test accuracy: 0.703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10.. Train loss: 0.791.. Test loss: 0.812.. Test accuracy: 0.705\n",
      "Epoch 7/10.. Train loss: 0.852.. Test loss: 0.813.. Test accuracy: 0.706\n",
      "Epoch 7/10.. Train loss: 0.791.. Test loss: 0.801.. Test accuracy: 0.707\n",
      "Epoch 7/10.. Train loss: 0.831.. Test loss: 0.799.. Test accuracy: 0.708\n",
      "Epoch 7/10.. Train loss: 0.770.. Test loss: 0.796.. Test accuracy: 0.711\n",
      "Epoch 7/10.. Train loss: 0.889.. Test loss: 0.815.. Test accuracy: 0.700\n",
      "Epoch 7/10.. Train loss: 0.787.. Test loss: 0.803.. Test accuracy: 0.704\n",
      "Epoch 7/10.. Train loss: 0.758.. Test loss: 0.816.. Test accuracy: 0.704\n",
      "Epoch 7/10.. Train loss: 0.795.. Test loss: 0.812.. Test accuracy: 0.704\n",
      "Epoch 7/10.. Train loss: 0.814.. Test loss: 0.817.. Test accuracy: 0.701\n",
      "Epoch 7/10.. Train loss: 0.775.. Test loss: 0.823.. Test accuracy: 0.699\n",
      "Epoch 7/10.. Train loss: 0.704.. Test loss: 0.804.. Test accuracy: 0.707\n",
      "Epoch 7/10.. Train loss: 0.847.. Test loss: 0.798.. Test accuracy: 0.708\n",
      "Epoch 7/10.. Train loss: 0.774.. Test loss: 0.814.. Test accuracy: 0.701\n",
      "Epoch 7/10.. Train loss: 0.837.. Test loss: 0.836.. Test accuracy: 0.698\n",
      "Epoch 7/10.. Train loss: 0.837.. Test loss: 0.795.. Test accuracy: 0.712\n",
      "Epoch 7/10.. Train loss: 0.793.. Test loss: 0.801.. Test accuracy: 0.711\n",
      "Epoch 7/10.. Train loss: 0.818.. Test loss: 0.822.. Test accuracy: 0.701\n",
      "Epoch 7/10.. Train loss: 0.836.. Test loss: 0.823.. Test accuracy: 0.699\n",
      "Epoch 7/10.. Train loss: 0.790.. Test loss: 0.812.. Test accuracy: 0.706\n",
      "Epoch 7/10.. Train loss: 0.809.. Test loss: 0.811.. Test accuracy: 0.704\n",
      "Epoch 7/10.. Train loss: 0.783.. Test loss: 0.823.. Test accuracy: 0.703\n",
      "Epoch 7/10.. Train loss: 0.810.. Test loss: 0.802.. Test accuracy: 0.710\n",
      "Epoch 7/10.. Train loss: 0.839.. Test loss: 0.809.. Test accuracy: 0.706\n",
      "Epoch 7/10.. Train loss: 0.829.. Test loss: 0.816.. Test accuracy: 0.704\n",
      "Epoch 7/10.. Train loss: 0.827.. Test loss: 0.808.. Test accuracy: 0.706\n",
      "Epoch 7/10.. Train loss: 0.791.. Test loss: 0.807.. Test accuracy: 0.710\n",
      "Epoch 7/10.. Train loss: 0.781.. Test loss: 0.799.. Test accuracy: 0.713\n",
      "Epoch 7/10.. Train loss: 0.753.. Test loss: 0.796.. Test accuracy: 0.716\n",
      "Epoch 7/10.. Train loss: 0.782.. Test loss: 0.807.. Test accuracy: 0.711\n",
      "Epoch 7/10.. Train loss: 0.775.. Test loss: 0.803.. Test accuracy: 0.716\n",
      "Epoch 7/10.. Train loss: 0.739.. Test loss: 0.797.. Test accuracy: 0.715\n",
      "Epoch 7/10.. Train loss: 0.811.. Test loss: 0.808.. Test accuracy: 0.713\n",
      "Epoch 7/10.. Train loss: 0.827.. Test loss: 0.802.. Test accuracy: 0.712\n",
      "Epoch 7/10.. Train loss: 0.823.. Test loss: 0.806.. Test accuracy: 0.705\n",
      "Epoch 7/10.. Train loss: 0.815.. Test loss: 0.783.. Test accuracy: 0.710\n",
      "Epoch 7/10.. Train loss: 0.799.. Test loss: 0.790.. Test accuracy: 0.712\n",
      "Epoch 7/10.. Train loss: 0.768.. Test loss: 0.792.. Test accuracy: 0.712\n",
      "Epoch 7/10.. Train loss: 0.856.. Test loss: 0.784.. Test accuracy: 0.715\n",
      "Epoch 7/10.. Train loss: 0.905.. Test loss: 0.785.. Test accuracy: 0.713\n",
      "Epoch 7/10.. Train loss: 0.795.. Test loss: 0.799.. Test accuracy: 0.712\n",
      "Epoch 7/10.. Train loss: 0.744.. Test loss: 0.801.. Test accuracy: 0.708\n",
      "Epoch 7/10.. Train loss: 0.814.. Test loss: 0.830.. Test accuracy: 0.703\n",
      "Epoch 7/10.. Train loss: 0.803.. Test loss: 0.791.. Test accuracy: 0.709\n",
      "Epoch 7/10.. Train loss: 0.809.. Test loss: 0.819.. Test accuracy: 0.704\n",
      "Epoch 7/10.. Train loss: 0.931.. Test loss: 0.793.. Test accuracy: 0.711\n",
      "Epoch 7/10.. Train loss: 0.799.. Test loss: 0.797.. Test accuracy: 0.706\n",
      "Epoch 7/10.. Train loss: 0.779.. Test loss: 0.803.. Test accuracy: 0.709\n",
      "Epoch 7/10.. Train loss: 0.732.. Test loss: 0.804.. Test accuracy: 0.703\n",
      "Epoch 7/10.. Train loss: 0.841.. Test loss: 0.810.. Test accuracy: 0.705\n",
      "Epoch 7/10.. Train loss: 0.866.. Test loss: 0.816.. Test accuracy: 0.705\n",
      "Epoch 7/10.. Train loss: 0.822.. Test loss: 0.807.. Test accuracy: 0.703\n",
      "Epoch 7/10.. Train loss: 0.779.. Test loss: 0.803.. Test accuracy: 0.707\n",
      "Epoch 7/10.. Train loss: 0.840.. Test loss: 0.792.. Test accuracy: 0.712\n",
      "Epoch 7/10.. Train loss: 0.770.. Test loss: 0.810.. Test accuracy: 0.706\n",
      "Epoch 7/10.. Train loss: 0.817.. Test loss: 0.800.. Test accuracy: 0.707\n",
      "Epoch 7/10.. Train loss: 0.816.. Test loss: 0.782.. Test accuracy: 0.712\n",
      "Epoch 7/10.. Train loss: 0.755.. Test loss: 0.790.. Test accuracy: 0.710\n",
      "Epoch 7/10.. Train loss: 0.746.. Test loss: 0.806.. Test accuracy: 0.699\n",
      "Epoch 7/10.. Train loss: 0.833.. Test loss: 0.789.. Test accuracy: 0.709\n",
      "Epoch 7/10.. Train loss: 0.756.. Test loss: 0.818.. Test accuracy: 0.708\n",
      "Epoch 7/10.. Train loss: 0.789.. Test loss: 0.799.. Test accuracy: 0.707\n",
      "Epoch 7/10.. Train loss: 0.810.. Test loss: 0.799.. Test accuracy: 0.705\n",
      "Epoch 7/10.. Train loss: 0.823.. Test loss: 0.786.. Test accuracy: 0.715\n",
      "Epoch 7/10.. Train loss: 0.873.. Test loss: 0.788.. Test accuracy: 0.708\n",
      "Epoch 7/10.. Train loss: 0.799.. Test loss: 0.793.. Test accuracy: 0.709\n",
      "Epoch 7/10.. Train loss: 0.809.. Test loss: 0.811.. Test accuracy: 0.710\n",
      "Epoch 7/10.. Train loss: 0.739.. Test loss: 0.802.. Test accuracy: 0.712\n",
      "Epoch 7/10.. Train loss: 0.897.. Test loss: 0.809.. Test accuracy: 0.705\n",
      "Epoch 7/10.. Train loss: 0.768.. Test loss: 0.809.. Test accuracy: 0.705\n",
      "Epoch 7/10.. Train loss: 0.807.. Test loss: 0.815.. Test accuracy: 0.700\n",
      "Epoch 7/10.. Train loss: 0.869.. Test loss: 0.808.. Test accuracy: 0.701\n",
      "Epoch 7/10.. Train loss: 0.826.. Test loss: 0.801.. Test accuracy: 0.705\n",
      "Epoch 7/10.. Train loss: 0.780.. Test loss: 0.792.. Test accuracy: 0.710\n",
      "Epoch 7/10.. Train loss: 0.785.. Test loss: 0.808.. Test accuracy: 0.705\n",
      "Epoch 7/10.. Train loss: 0.857.. Test loss: 0.798.. Test accuracy: 0.711\n",
      "Epoch 7/10.. Train loss: 0.809.. Test loss: 0.811.. Test accuracy: 0.704\n",
      "Epoch 7/10.. Train loss: 0.858.. Test loss: 0.804.. Test accuracy: 0.708\n",
      "Epoch 7/10.. Train loss: 0.767.. Test loss: 0.801.. Test accuracy: 0.700\n",
      "Epoch 7/10.. Train loss: 0.784.. Test loss: 0.812.. Test accuracy: 0.707\n",
      "Epoch 7/10.. Train loss: 0.852.. Test loss: 0.801.. Test accuracy: 0.709\n",
      "Epoch 7/10.. Train loss: 0.816.. Test loss: 0.803.. Test accuracy: 0.710\n",
      "Epoch 7/10.. Train loss: 0.762.. Test loss: 0.781.. Test accuracy: 0.713\n",
      "Epoch 7/10.. Train loss: 0.840.. Test loss: 0.800.. Test accuracy: 0.709\n",
      "Epoch 7/10.. Train loss: 0.813.. Test loss: 0.803.. Test accuracy: 0.711\n",
      "Epoch 7/10.. Train loss: 0.867.. Test loss: 0.816.. Test accuracy: 0.704\n",
      "Epoch 7/10.. Train loss: 0.827.. Test loss: 0.790.. Test accuracy: 0.711\n",
      "Epoch 7/10.. Train loss: 0.763.. Test loss: 0.822.. Test accuracy: 0.703\n",
      "Epoch 7/10.. Train loss: 0.815.. Test loss: 0.799.. Test accuracy: 0.713\n",
      "Epoch 7/10.. Train loss: 0.821.. Test loss: 0.789.. Test accuracy: 0.712\n",
      "Epoch 7/10.. Train loss: 0.833.. Test loss: 0.804.. Test accuracy: 0.708\n",
      "Epoch 8/10.. Train loss: 0.336.. Test loss: 0.803.. Test accuracy: 0.709\n",
      "Epoch 8/10.. Train loss: 0.820.. Test loss: 0.805.. Test accuracy: 0.706\n",
      "Epoch 8/10.. Train loss: 0.793.. Test loss: 0.794.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.762.. Test loss: 0.805.. Test accuracy: 0.714\n",
      "Epoch 8/10.. Train loss: 0.875.. Test loss: 0.823.. Test accuracy: 0.707\n",
      "Epoch 8/10.. Train loss: 0.758.. Test loss: 0.811.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.756.. Test loss: 0.796.. Test accuracy: 0.706\n",
      "Epoch 8/10.. Train loss: 0.834.. Test loss: 0.798.. Test accuracy: 0.702\n",
      "Epoch 8/10.. Train loss: 0.836.. Test loss: 0.790.. Test accuracy: 0.709\n",
      "Epoch 8/10.. Train loss: 0.802.. Test loss: 0.802.. Test accuracy: 0.705\n",
      "Epoch 8/10.. Train loss: 0.705.. Test loss: 0.791.. Test accuracy: 0.712\n",
      "Epoch 8/10.. Train loss: 0.821.. Test loss: 0.790.. Test accuracy: 0.709\n",
      "Epoch 8/10.. Train loss: 0.797.. Test loss: 0.787.. Test accuracy: 0.709\n",
      "Epoch 8/10.. Train loss: 0.786.. Test loss: 0.809.. Test accuracy: 0.704\n",
      "Epoch 8/10.. Train loss: 0.831.. Test loss: 0.796.. Test accuracy: 0.710\n",
      "Epoch 8/10.. Train loss: 0.807.. Test loss: 0.782.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.812.. Test loss: 0.794.. Test accuracy: 0.712\n",
      "Epoch 8/10.. Train loss: 0.760.. Test loss: 0.798.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.760.. Test loss: 0.804.. Test accuracy: 0.716\n",
      "Epoch 8/10.. Train loss: 0.823.. Test loss: 0.796.. Test accuracy: 0.714\n",
      "Epoch 8/10.. Train loss: 0.798.. Test loss: 0.807.. Test accuracy: 0.706\n",
      "Epoch 8/10.. Train loss: 0.757.. Test loss: 0.805.. Test accuracy: 0.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10.. Train loss: 0.797.. Test loss: 0.792.. Test accuracy: 0.712\n",
      "Epoch 8/10.. Train loss: 0.766.. Test loss: 0.786.. Test accuracy: 0.714\n",
      "Epoch 8/10.. Train loss: 0.789.. Test loss: 0.806.. Test accuracy: 0.705\n",
      "Epoch 8/10.. Train loss: 0.747.. Test loss: 0.808.. Test accuracy: 0.708\n",
      "Epoch 8/10.. Train loss: 0.818.. Test loss: 0.812.. Test accuracy: 0.706\n",
      "Epoch 8/10.. Train loss: 0.726.. Test loss: 0.806.. Test accuracy: 0.708\n",
      "Epoch 8/10.. Train loss: 0.753.. Test loss: 0.800.. Test accuracy: 0.710\n",
      "Epoch 8/10.. Train loss: 0.766.. Test loss: 0.788.. Test accuracy: 0.711\n",
      "Epoch 8/10.. Train loss: 0.760.. Test loss: 0.801.. Test accuracy: 0.712\n",
      "Epoch 8/10.. Train loss: 0.802.. Test loss: 0.804.. Test accuracy: 0.706\n",
      "Epoch 8/10.. Train loss: 0.817.. Test loss: 0.800.. Test accuracy: 0.707\n",
      "Epoch 8/10.. Train loss: 0.749.. Test loss: 0.799.. Test accuracy: 0.707\n",
      "Epoch 8/10.. Train loss: 0.751.. Test loss: 0.790.. Test accuracy: 0.712\n",
      "Epoch 8/10.. Train loss: 0.725.. Test loss: 0.792.. Test accuracy: 0.718\n",
      "Epoch 8/10.. Train loss: 0.837.. Test loss: 0.803.. Test accuracy: 0.707\n",
      "Epoch 8/10.. Train loss: 0.755.. Test loss: 0.787.. Test accuracy: 0.717\n",
      "Epoch 8/10.. Train loss: 0.810.. Test loss: 0.789.. Test accuracy: 0.709\n",
      "Epoch 8/10.. Train loss: 0.793.. Test loss: 0.791.. Test accuracy: 0.712\n",
      "Epoch 8/10.. Train loss: 0.810.. Test loss: 0.792.. Test accuracy: 0.708\n",
      "Epoch 8/10.. Train loss: 0.752.. Test loss: 0.796.. Test accuracy: 0.707\n",
      "Epoch 8/10.. Train loss: 0.867.. Test loss: 0.781.. Test accuracy: 0.716\n",
      "Epoch 8/10.. Train loss: 0.771.. Test loss: 0.792.. Test accuracy: 0.711\n",
      "Epoch 8/10.. Train loss: 0.770.. Test loss: 0.797.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.746.. Test loss: 0.795.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.785.. Test loss: 0.795.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.791.. Test loss: 0.804.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.762.. Test loss: 0.805.. Test accuracy: 0.712\n",
      "Epoch 8/10.. Train loss: 0.746.. Test loss: 0.793.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.824.. Test loss: 0.791.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.840.. Test loss: 0.798.. Test accuracy: 0.708\n",
      "Epoch 8/10.. Train loss: 0.779.. Test loss: 0.817.. Test accuracy: 0.702\n",
      "Epoch 8/10.. Train loss: 0.789.. Test loss: 0.810.. Test accuracy: 0.705\n",
      "Epoch 8/10.. Train loss: 0.793.. Test loss: 0.785.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.773.. Test loss: 0.808.. Test accuracy: 0.705\n",
      "Epoch 8/10.. Train loss: 0.836.. Test loss: 0.813.. Test accuracy: 0.705\n",
      "Epoch 8/10.. Train loss: 0.730.. Test loss: 0.797.. Test accuracy: 0.712\n",
      "Epoch 8/10.. Train loss: 0.752.. Test loss: 0.791.. Test accuracy: 0.715\n",
      "Epoch 8/10.. Train loss: 0.794.. Test loss: 0.786.. Test accuracy: 0.715\n",
      "Epoch 8/10.. Train loss: 0.745.. Test loss: 0.807.. Test accuracy: 0.710\n",
      "Epoch 8/10.. Train loss: 0.809.. Test loss: 0.793.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.798.. Test loss: 0.818.. Test accuracy: 0.703\n",
      "Epoch 8/10.. Train loss: 0.856.. Test loss: 0.794.. Test accuracy: 0.708\n",
      "Epoch 8/10.. Train loss: 0.747.. Test loss: 0.785.. Test accuracy: 0.711\n",
      "Epoch 8/10.. Train loss: 0.809.. Test loss: 0.797.. Test accuracy: 0.710\n",
      "Epoch 8/10.. Train loss: 0.841.. Test loss: 0.786.. Test accuracy: 0.710\n",
      "Epoch 8/10.. Train loss: 0.764.. Test loss: 0.787.. Test accuracy: 0.711\n",
      "Epoch 8/10.. Train loss: 0.741.. Test loss: 0.785.. Test accuracy: 0.717\n",
      "Epoch 8/10.. Train loss: 0.756.. Test loss: 0.787.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.767.. Test loss: 0.804.. Test accuracy: 0.708\n",
      "Epoch 8/10.. Train loss: 0.833.. Test loss: 0.789.. Test accuracy: 0.715\n",
      "Epoch 8/10.. Train loss: 0.763.. Test loss: 0.807.. Test accuracy: 0.712\n",
      "Epoch 8/10.. Train loss: 0.791.. Test loss: 0.798.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.749.. Test loss: 0.813.. Test accuracy: 0.706\n",
      "Epoch 8/10.. Train loss: 0.735.. Test loss: 0.810.. Test accuracy: 0.711\n",
      "Epoch 8/10.. Train loss: 0.823.. Test loss: 0.784.. Test accuracy: 0.716\n",
      "Epoch 8/10.. Train loss: 0.825.. Test loss: 0.794.. Test accuracy: 0.712\n",
      "Epoch 8/10.. Train loss: 0.881.. Test loss: 0.785.. Test accuracy: 0.708\n",
      "Epoch 8/10.. Train loss: 0.822.. Test loss: 0.789.. Test accuracy: 0.711\n",
      "Epoch 8/10.. Train loss: 0.822.. Test loss: 0.792.. Test accuracy: 0.708\n",
      "Epoch 8/10.. Train loss: 0.823.. Test loss: 0.808.. Test accuracy: 0.706\n",
      "Epoch 8/10.. Train loss: 0.740.. Test loss: 0.818.. Test accuracy: 0.710\n",
      "Epoch 8/10.. Train loss: 0.812.. Test loss: 0.786.. Test accuracy: 0.712\n",
      "Epoch 8/10.. Train loss: 0.758.. Test loss: 0.791.. Test accuracy: 0.705\n",
      "Epoch 8/10.. Train loss: 0.791.. Test loss: 0.796.. Test accuracy: 0.714\n",
      "Epoch 8/10.. Train loss: 0.793.. Test loss: 0.775.. Test accuracy: 0.715\n",
      "Epoch 8/10.. Train loss: 0.800.. Test loss: 0.771.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.821.. Test loss: 0.780.. Test accuracy: 0.711\n",
      "Epoch 8/10.. Train loss: 0.771.. Test loss: 0.809.. Test accuracy: 0.702\n",
      "Epoch 8/10.. Train loss: 0.834.. Test loss: 0.809.. Test accuracy: 0.704\n",
      "Epoch 8/10.. Train loss: 0.807.. Test loss: 0.783.. Test accuracy: 0.711\n",
      "Epoch 8/10.. Train loss: 0.882.. Test loss: 0.792.. Test accuracy: 0.713\n",
      "Epoch 8/10.. Train loss: 0.816.. Test loss: 0.782.. Test accuracy: 0.711\n",
      "Epoch 9/10.. Train loss: 0.492.. Test loss: 0.794.. Test accuracy: 0.703\n",
      "Epoch 9/10.. Train loss: 0.712.. Test loss: 0.778.. Test accuracy: 0.711\n",
      "Epoch 9/10.. Train loss: 0.809.. Test loss: 0.790.. Test accuracy: 0.710\n",
      "Epoch 9/10.. Train loss: 0.753.. Test loss: 0.793.. Test accuracy: 0.712\n",
      "Epoch 9/10.. Train loss: 0.713.. Test loss: 0.787.. Test accuracy: 0.714\n",
      "Epoch 9/10.. Train loss: 0.733.. Test loss: 0.790.. Test accuracy: 0.712\n",
      "Epoch 9/10.. Train loss: 0.794.. Test loss: 0.781.. Test accuracy: 0.719\n",
      "Epoch 9/10.. Train loss: 0.806.. Test loss: 0.795.. Test accuracy: 0.714\n",
      "Epoch 9/10.. Train loss: 0.716.. Test loss: 0.778.. Test accuracy: 0.719\n",
      "Epoch 9/10.. Train loss: 0.756.. Test loss: 0.788.. Test accuracy: 0.716\n",
      "Epoch 9/10.. Train loss: 0.819.. Test loss: 0.793.. Test accuracy: 0.715\n",
      "Epoch 9/10.. Train loss: 0.820.. Test loss: 0.809.. Test accuracy: 0.706\n",
      "Epoch 9/10.. Train loss: 0.716.. Test loss: 0.790.. Test accuracy: 0.711\n",
      "Epoch 9/10.. Train loss: 0.781.. Test loss: 0.804.. Test accuracy: 0.704\n",
      "Epoch 9/10.. Train loss: 0.774.. Test loss: 0.798.. Test accuracy: 0.710\n",
      "Epoch 9/10.. Train loss: 0.765.. Test loss: 0.793.. Test accuracy: 0.710\n",
      "Epoch 9/10.. Train loss: 0.783.. Test loss: 0.792.. Test accuracy: 0.711\n",
      "Epoch 9/10.. Train loss: 0.766.. Test loss: 0.788.. Test accuracy: 0.709\n",
      "Epoch 9/10.. Train loss: 0.735.. Test loss: 0.795.. Test accuracy: 0.709\n",
      "Epoch 9/10.. Train loss: 0.794.. Test loss: 0.772.. Test accuracy: 0.716\n",
      "Epoch 9/10.. Train loss: 0.745.. Test loss: 0.788.. Test accuracy: 0.712\n",
      "Epoch 9/10.. Train loss: 0.807.. Test loss: 0.778.. Test accuracy: 0.719\n",
      "Epoch 9/10.. Train loss: 0.783.. Test loss: 0.789.. Test accuracy: 0.713\n",
      "Epoch 9/10.. Train loss: 0.720.. Test loss: 0.798.. Test accuracy: 0.707\n",
      "Epoch 9/10.. Train loss: 0.786.. Test loss: 0.804.. Test accuracy: 0.706\n",
      "Epoch 9/10.. Train loss: 0.734.. Test loss: 0.791.. Test accuracy: 0.709\n",
      "Epoch 9/10.. Train loss: 0.746.. Test loss: 0.799.. Test accuracy: 0.707\n",
      "Epoch 9/10.. Train loss: 0.771.. Test loss: 0.793.. Test accuracy: 0.707\n",
      "Epoch 9/10.. Train loss: 0.798.. Test loss: 0.796.. Test accuracy: 0.710\n",
      "Epoch 9/10.. Train loss: 0.779.. Test loss: 0.781.. Test accuracy: 0.714\n",
      "Epoch 9/10.. Train loss: 0.724.. Test loss: 0.795.. Test accuracy: 0.712\n",
      "Epoch 9/10.. Train loss: 0.757.. Test loss: 0.790.. Test accuracy: 0.717\n",
      "Epoch 9/10.. Train loss: 0.765.. Test loss: 0.781.. Test accuracy: 0.717\n",
      "Epoch 9/10.. Train loss: 0.761.. Test loss: 0.778.. Test accuracy: 0.718\n",
      "Epoch 9/10.. Train loss: 0.749.. Test loss: 0.781.. Test accuracy: 0.714\n",
      "Epoch 9/10.. Train loss: 0.726.. Test loss: 0.789.. Test accuracy: 0.709\n",
      "Epoch 9/10.. Train loss: 0.810.. Test loss: 0.786.. Test accuracy: 0.713\n",
      "Epoch 9/10.. Train loss: 0.773.. Test loss: 0.788.. Test accuracy: 0.709\n",
      "Epoch 9/10.. Train loss: 0.800.. Test loss: 0.814.. Test accuracy: 0.709\n",
      "Epoch 9/10.. Train loss: 0.770.. Test loss: 0.793.. Test accuracy: 0.708\n",
      "Epoch 9/10.. Train loss: 0.729.. Test loss: 0.793.. Test accuracy: 0.709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10.. Train loss: 0.861.. Test loss: 0.794.. Test accuracy: 0.712\n",
      "Epoch 9/10.. Train loss: 0.776.. Test loss: 0.802.. Test accuracy: 0.707\n",
      "Epoch 9/10.. Train loss: 0.910.. Test loss: 0.781.. Test accuracy: 0.711\n",
      "Epoch 9/10.. Train loss: 0.857.. Test loss: 0.800.. Test accuracy: 0.705\n",
      "Epoch 9/10.. Train loss: 0.783.. Test loss: 0.790.. Test accuracy: 0.716\n",
      "Epoch 9/10.. Train loss: 0.805.. Test loss: 0.774.. Test accuracy: 0.718\n",
      "Epoch 9/10.. Train loss: 0.817.. Test loss: 0.787.. Test accuracy: 0.713\n",
      "Epoch 9/10.. Train loss: 0.810.. Test loss: 0.779.. Test accuracy: 0.717\n",
      "Epoch 9/10.. Train loss: 0.789.. Test loss: 0.775.. Test accuracy: 0.715\n",
      "Epoch 9/10.. Train loss: 0.840.. Test loss: 0.774.. Test accuracy: 0.715\n",
      "Epoch 9/10.. Train loss: 0.758.. Test loss: 0.776.. Test accuracy: 0.718\n",
      "Epoch 9/10.. Train loss: 0.781.. Test loss: 0.789.. Test accuracy: 0.712\n",
      "Epoch 9/10.. Train loss: 0.836.. Test loss: 0.800.. Test accuracy: 0.704\n",
      "Epoch 9/10.. Train loss: 0.867.. Test loss: 0.797.. Test accuracy: 0.710\n",
      "Epoch 9/10.. Train loss: 0.730.. Test loss: 0.791.. Test accuracy: 0.710\n",
      "Epoch 9/10.. Train loss: 0.776.. Test loss: 0.793.. Test accuracy: 0.712\n",
      "Epoch 9/10.. Train loss: 0.770.. Test loss: 0.784.. Test accuracy: 0.716\n",
      "Epoch 9/10.. Train loss: 0.722.. Test loss: 0.789.. Test accuracy: 0.712\n",
      "Epoch 9/10.. Train loss: 0.779.. Test loss: 0.812.. Test accuracy: 0.707\n",
      "Epoch 9/10.. Train loss: 0.796.. Test loss: 0.822.. Test accuracy: 0.711\n",
      "Epoch 9/10.. Train loss: 0.746.. Test loss: 0.802.. Test accuracy: 0.713\n",
      "Epoch 9/10.. Train loss: 0.884.. Test loss: 0.776.. Test accuracy: 0.722\n",
      "Epoch 9/10.. Train loss: 0.742.. Test loss: 0.802.. Test accuracy: 0.711\n",
      "Epoch 9/10.. Train loss: 0.752.. Test loss: 0.787.. Test accuracy: 0.714\n",
      "Epoch 9/10.. Train loss: 0.768.. Test loss: 0.796.. Test accuracy: 0.709\n",
      "Epoch 9/10.. Train loss: 0.821.. Test loss: 0.807.. Test accuracy: 0.706\n",
      "Epoch 9/10.. Train loss: 0.767.. Test loss: 0.790.. Test accuracy: 0.710\n",
      "Epoch 9/10.. Train loss: 0.729.. Test loss: 0.790.. Test accuracy: 0.712\n",
      "Epoch 9/10.. Train loss: 0.757.. Test loss: 0.810.. Test accuracy: 0.711\n",
      "Epoch 9/10.. Train loss: 0.717.. Test loss: 0.798.. Test accuracy: 0.714\n",
      "Epoch 9/10.. Train loss: 0.834.. Test loss: 0.794.. Test accuracy: 0.708\n",
      "Epoch 9/10.. Train loss: 0.780.. Test loss: 0.792.. Test accuracy: 0.707\n",
      "Epoch 9/10.. Train loss: 0.823.. Test loss: 0.786.. Test accuracy: 0.712\n",
      "Epoch 9/10.. Train loss: 0.793.. Test loss: 0.794.. Test accuracy: 0.712\n",
      "Epoch 9/10.. Train loss: 0.763.. Test loss: 0.785.. Test accuracy: 0.714\n",
      "Epoch 9/10.. Train loss: 0.784.. Test loss: 0.776.. Test accuracy: 0.716\n",
      "Epoch 9/10.. Train loss: 0.784.. Test loss: 0.792.. Test accuracy: 0.711\n",
      "Epoch 9/10.. Train loss: 0.779.. Test loss: 0.792.. Test accuracy: 0.710\n",
      "Epoch 9/10.. Train loss: 0.769.. Test loss: 0.794.. Test accuracy: 0.712\n",
      "Epoch 9/10.. Train loss: 0.826.. Test loss: 0.794.. Test accuracy: 0.708\n",
      "Epoch 9/10.. Train loss: 0.718.. Test loss: 0.790.. Test accuracy: 0.711\n",
      "Epoch 9/10.. Train loss: 0.804.. Test loss: 0.808.. Test accuracy: 0.709\n",
      "Epoch 9/10.. Train loss: 0.800.. Test loss: 0.798.. Test accuracy: 0.709\n",
      "Epoch 9/10.. Train loss: 0.771.. Test loss: 0.807.. Test accuracy: 0.711\n",
      "Epoch 9/10.. Train loss: 0.856.. Test loss: 0.790.. Test accuracy: 0.713\n",
      "Epoch 9/10.. Train loss: 0.790.. Test loss: 0.804.. Test accuracy: 0.707\n",
      "Epoch 9/10.. Train loss: 0.813.. Test loss: 0.803.. Test accuracy: 0.705\n",
      "Epoch 9/10.. Train loss: 0.780.. Test loss: 0.795.. Test accuracy: 0.706\n",
      "Epoch 9/10.. Train loss: 0.795.. Test loss: 0.805.. Test accuracy: 0.703\n",
      "Epoch 9/10.. Train loss: 0.806.. Test loss: 0.795.. Test accuracy: 0.703\n",
      "Epoch 9/10.. Train loss: 0.812.. Test loss: 0.795.. Test accuracy: 0.707\n",
      "Epoch 9/10.. Train loss: 0.826.. Test loss: 0.778.. Test accuracy: 0.709\n",
      "Epoch 9/10.. Train loss: 0.822.. Test loss: 0.772.. Test accuracy: 0.711\n",
      "Epoch 10/10.. Train loss: 0.648.. Test loss: 0.769.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.758.. Test loss: 0.783.. Test accuracy: 0.712\n",
      "Epoch 10/10.. Train loss: 0.794.. Test loss: 0.785.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.733.. Test loss: 0.793.. Test accuracy: 0.712\n",
      "Epoch 10/10.. Train loss: 0.734.. Test loss: 0.792.. Test accuracy: 0.708\n",
      "Epoch 10/10.. Train loss: 0.692.. Test loss: 0.789.. Test accuracy: 0.710\n",
      "Epoch 10/10.. Train loss: 0.696.. Test loss: 0.804.. Test accuracy: 0.708\n",
      "Epoch 10/10.. Train loss: 0.815.. Test loss: 0.781.. Test accuracy: 0.714\n",
      "Epoch 10/10.. Train loss: 0.786.. Test loss: 0.783.. Test accuracy: 0.711\n",
      "Epoch 10/10.. Train loss: 0.806.. Test loss: 0.784.. Test accuracy: 0.707\n",
      "Epoch 10/10.. Train loss: 0.743.. Test loss: 0.784.. Test accuracy: 0.711\n",
      "Epoch 10/10.. Train loss: 0.793.. Test loss: 0.802.. Test accuracy: 0.710\n",
      "Epoch 10/10.. Train loss: 0.850.. Test loss: 0.796.. Test accuracy: 0.708\n",
      "Epoch 10/10.. Train loss: 0.767.. Test loss: 0.791.. Test accuracy: 0.712\n",
      "Epoch 10/10.. Train loss: 0.724.. Test loss: 0.786.. Test accuracy: 0.714\n",
      "Epoch 10/10.. Train loss: 0.730.. Test loss: 0.783.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.717.. Test loss: 0.791.. Test accuracy: 0.712\n",
      "Epoch 10/10.. Train loss: 0.776.. Test loss: 0.800.. Test accuracy: 0.712\n",
      "Epoch 10/10.. Train loss: 0.796.. Test loss: 0.799.. Test accuracy: 0.712\n",
      "Epoch 10/10.. Train loss: 0.711.. Test loss: 0.781.. Test accuracy: 0.717\n",
      "Epoch 10/10.. Train loss: 0.703.. Test loss: 0.789.. Test accuracy: 0.713\n",
      "Epoch 10/10.. Train loss: 0.765.. Test loss: 0.783.. Test accuracy: 0.720\n",
      "Epoch 10/10.. Train loss: 0.699.. Test loss: 0.790.. Test accuracy: 0.713\n",
      "Epoch 10/10.. Train loss: 0.790.. Test loss: 0.785.. Test accuracy: 0.714\n",
      "Epoch 10/10.. Train loss: 0.783.. Test loss: 0.780.. Test accuracy: 0.714\n",
      "Epoch 10/10.. Train loss: 0.810.. Test loss: 0.806.. Test accuracy: 0.702\n",
      "Epoch 10/10.. Train loss: 0.763.. Test loss: 0.785.. Test accuracy: 0.710\n",
      "Epoch 10/10.. Train loss: 0.817.. Test loss: 0.771.. Test accuracy: 0.718\n",
      "Epoch 10/10.. Train loss: 0.759.. Test loss: 0.784.. Test accuracy: 0.711\n",
      "Epoch 10/10.. Train loss: 0.806.. Test loss: 0.792.. Test accuracy: 0.716\n",
      "Epoch 10/10.. Train loss: 0.806.. Test loss: 0.782.. Test accuracy: 0.717\n",
      "Epoch 10/10.. Train loss: 0.761.. Test loss: 0.782.. Test accuracy: 0.717\n",
      "Epoch 10/10.. Train loss: 0.769.. Test loss: 0.789.. Test accuracy: 0.712\n",
      "Epoch 10/10.. Train loss: 0.802.. Test loss: 0.787.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.825.. Test loss: 0.786.. Test accuracy: 0.709\n",
      "Epoch 10/10.. Train loss: 0.737.. Test loss: 0.783.. Test accuracy: 0.716\n",
      "Epoch 10/10.. Train loss: 0.822.. Test loss: 0.773.. Test accuracy: 0.714\n",
      "Epoch 10/10.. Train loss: 0.811.. Test loss: 0.774.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.772.. Test loss: 0.797.. Test accuracy: 0.714\n",
      "Epoch 10/10.. Train loss: 0.853.. Test loss: 0.789.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.842.. Test loss: 0.791.. Test accuracy: 0.710\n",
      "Epoch 10/10.. Train loss: 0.755.. Test loss: 0.820.. Test accuracy: 0.699\n",
      "Epoch 10/10.. Train loss: 0.714.. Test loss: 0.778.. Test accuracy: 0.714\n",
      "Epoch 10/10.. Train loss: 0.710.. Test loss: 0.789.. Test accuracy: 0.713\n",
      "Epoch 10/10.. Train loss: 0.721.. Test loss: 0.783.. Test accuracy: 0.720\n",
      "Epoch 10/10.. Train loss: 0.761.. Test loss: 0.781.. Test accuracy: 0.719\n",
      "Epoch 10/10.. Train loss: 0.874.. Test loss: 0.782.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.805.. Test loss: 0.776.. Test accuracy: 0.716\n",
      "Epoch 10/10.. Train loss: 0.744.. Test loss: 0.797.. Test accuracy: 0.708\n",
      "Epoch 10/10.. Train loss: 0.824.. Test loss: 0.797.. Test accuracy: 0.707\n",
      "Epoch 10/10.. Train loss: 0.799.. Test loss: 0.798.. Test accuracy: 0.709\n",
      "Epoch 10/10.. Train loss: 0.768.. Test loss: 0.786.. Test accuracy: 0.713\n",
      "Epoch 10/10.. Train loss: 0.809.. Test loss: 0.774.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.793.. Test loss: 0.785.. Test accuracy: 0.712\n",
      "Epoch 10/10.. Train loss: 0.772.. Test loss: 0.787.. Test accuracy: 0.711\n",
      "Epoch 10/10.. Train loss: 0.785.. Test loss: 0.784.. Test accuracy: 0.713\n",
      "Epoch 10/10.. Train loss: 0.779.. Test loss: 0.793.. Test accuracy: 0.710\n",
      "Epoch 10/10.. Train loss: 0.822.. Test loss: 0.787.. Test accuracy: 0.716\n",
      "Epoch 10/10.. Train loss: 0.819.. Test loss: 0.783.. Test accuracy: 0.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10.. Train loss: 0.815.. Test loss: 0.782.. Test accuracy: 0.709\n",
      "Epoch 10/10.. Train loss: 0.812.. Test loss: 0.771.. Test accuracy: 0.714\n",
      "Epoch 10/10.. Train loss: 0.782.. Test loss: 0.779.. Test accuracy: 0.713\n",
      "Epoch 10/10.. Train loss: 0.832.. Test loss: 0.775.. Test accuracy: 0.717\n",
      "Epoch 10/10.. Train loss: 0.808.. Test loss: 0.783.. Test accuracy: 0.720\n",
      "Epoch 10/10.. Train loss: 0.810.. Test loss: 0.796.. Test accuracy: 0.713\n",
      "Epoch 10/10.. Train loss: 0.763.. Test loss: 0.785.. Test accuracy: 0.710\n",
      "Epoch 10/10.. Train loss: 0.770.. Test loss: 0.789.. Test accuracy: 0.712\n",
      "Epoch 10/10.. Train loss: 0.760.. Test loss: 0.784.. Test accuracy: 0.711\n",
      "Epoch 10/10.. Train loss: 0.698.. Test loss: 0.784.. Test accuracy: 0.714\n",
      "Epoch 10/10.. Train loss: 0.814.. Test loss: 0.804.. Test accuracy: 0.714\n",
      "Epoch 10/10.. Train loss: 0.797.. Test loss: 0.795.. Test accuracy: 0.710\n",
      "Epoch 10/10.. Train loss: 0.829.. Test loss: 0.785.. Test accuracy: 0.712\n",
      "Epoch 10/10.. Train loss: 0.747.. Test loss: 0.772.. Test accuracy: 0.716\n",
      "Epoch 10/10.. Train loss: 0.771.. Test loss: 0.770.. Test accuracy: 0.718\n",
      "Epoch 10/10.. Train loss: 0.761.. Test loss: 0.777.. Test accuracy: 0.720\n",
      "Epoch 10/10.. Train loss: 0.734.. Test loss: 0.816.. Test accuracy: 0.706\n",
      "Epoch 10/10.. Train loss: 0.737.. Test loss: 0.796.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.797.. Test loss: 0.790.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.720.. Test loss: 0.815.. Test accuracy: 0.708\n",
      "Epoch 10/10.. Train loss: 0.763.. Test loss: 0.811.. Test accuracy: 0.711\n",
      "Epoch 10/10.. Train loss: 0.788.. Test loss: 0.795.. Test accuracy: 0.714\n",
      "Epoch 10/10.. Train loss: 0.798.. Test loss: 0.791.. Test accuracy: 0.710\n",
      "Epoch 10/10.. Train loss: 0.747.. Test loss: 0.794.. Test accuracy: 0.708\n",
      "Epoch 10/10.. Train loss: 0.814.. Test loss: 0.794.. Test accuracy: 0.709\n",
      "Epoch 10/10.. Train loss: 0.822.. Test loss: 0.788.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.755.. Test loss: 0.792.. Test accuracy: 0.713\n",
      "Epoch 10/10.. Train loss: 0.775.. Test loss: 0.783.. Test accuracy: 0.710\n",
      "Epoch 10/10.. Train loss: 0.778.. Test loss: 0.778.. Test accuracy: 0.716\n",
      "Epoch 10/10.. Train loss: 0.773.. Test loss: 0.781.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.828.. Test loss: 0.775.. Test accuracy: 0.710\n",
      "Epoch 10/10.. Train loss: 0.765.. Test loss: 0.796.. Test accuracy: 0.710\n",
      "Epoch 10/10.. Train loss: 0.812.. Test loss: 0.787.. Test accuracy: 0.706\n",
      "Epoch 10/10.. Train loss: 0.744.. Test loss: 0.773.. Test accuracy: 0.715\n",
      "Epoch 10/10.. Train loss: 0.711.. Test loss: 0.789.. Test accuracy: 0.717\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = [], []\n",
    "steps = 0\n",
    "print_every = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                for inputs, labels in test_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    \n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            \n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(test_loader))\n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(test_loader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(test_loader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "\n",
    "model_save_dir = 'model/'\n",
    "if not os.path.exists(model_save_dir):\n",
    "    os.makedirs(model_save_dir)\n",
    "\n",
    "torch.save(model, model_save_dir + 'resnet_classifier_shuffle.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_loss, label='Test Loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
